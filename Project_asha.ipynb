{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project asha.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO0hVI2bT/hEgK8ZfWzJTnr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astha77-bot/Project-asha/blob/master/Project_asha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lpd3GAvrnoPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9dwH1H1Jfm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer = LancasterStemmer()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM3bS7-GmPk3",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD3sb3ia3_EZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCdUuCbRpZry",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "a350b138-a4e3-4aef-cd7c-faef4e082907"
      },
      "source": [
        "!pip install tflearn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/ec/e9ce1b52e71f6dff3bd944f020cef7140779e783ab27512ea7c7275ddee5/tflearn-0.3.2.tar.gz (98kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 18.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (7.0.0)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.3.2-cp36-none-any.whl size=128208 sha256=fc67e9afa9800d0a90b23efe54f672ab68ca9e06df8b29b53ba2e94178468191\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/f6/69/0ef3ee395aac2e5d15d89efd29a9a216f3c27767b43b72c006\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce4fCCYB1jHD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5d1b868d-36f3-4557-b943-0be75a233e4f"
      },
      "source": [
        "!pip uninstall tensorflow -y\n",
        "!pip uninstall tensorflow-gpu -y\n",
        "!pip uninstall tflearn -y\n",
        "!pip install tensorflow-gpu==1.15\n",
        "!pip install tflearn"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.3.0:\n",
            "  Successfully uninstalled tensorflow-2.3.0\n",
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
            "Uninstalling tflearn-0.3.2:\n",
            "  Successfully uninstalled tflearn-0.3.2\n",
            "Collecting tensorflow-gpu==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/933140e74973fb917a194ab814785e7c23680ca5dee6d663a509fe9579b6/tensorflow_gpu-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.12.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.12.4)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 41.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.30.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.18.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.3.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (49.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=a2faebe1dab0ea75e92826e1945456609a3f4cc86bc83055fe991c2d4ba649f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, gast, keras-applications, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n",
            "Processing /root/.cache/pip/wheels/d0/f6/69/0ef3ee395aac2e5d15d89efd29a9a216f3c27767b43b72c006/tflearn-0.3.2-cp36-none-any.whl\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.18.5)\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjV3dGO82lfx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "81756733-a698-49a1-98e3-20e5a32b7404"
      },
      "source": [
        "import tflearn"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRyPRfzP6BNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy\n",
        "import tflearn\n",
        "import tensorflow\n",
        "import random"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JXakfQRGhv7I",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "83b46ef3-36fd-4ad8-8f7d-78db646b2693"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-80ec5ff1-3c91-4597-b676-37feda9bc6e3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-80ec5ff1-3c91-4597-b676-37feda9bc6e3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ashap.json to ashap.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r5kcRvCwiPO7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "d6cb5a0d-094d-41ad-b0a8-3f84c9823b2a"
      },
      "source": [
        "file_name = \"ashap.json\"\n",
        "uploaded[file_name].decode(\"utf-8\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\"intents\": [ \\r\\n    {\"tag\": \"greeting\",\\r\\n        \"patterns\": [\"Hi\", \"How are you\", \"Is anyone there?\", \"Hello\", \"Good day\", \"Whats up\"],\\r\\n        \"responses\": [ \"Hi there, how can I help?\"],\\r\\n        \"context_set\": \"\"\\r\\n       },\\r\\n       {\"tag\": \"goodbye\",\\r\\n        \"patterns\": [\"cya\", \"See you later\", \"Goodbye\", \"I am Leaving\", \"Have a Good day\"],\\r\\n        \"responses\": [\"Sad to see you go :(\", \"Talk to you later\", \"Goodbye!,I hope I helped you feel better in anyway :)\"],\\r\\n        \"context_set\": \"\"\\r\\n       },\\r\\n\\r\\n    {\"tag\":\"Suicide\",\\r\\n    \"patterns\": [\\r\\n      \"can i change my feeling of being worthless to everyone ? i \\' m going through some things with my feelings and myself . i barely sleep and i do nothing but think about how i \\' m worthless and how i shouldn \\' t be here . i \\' ve never tried or contemplated suicide . i \\' ve always wanted to fix my issues , but i never get around to it . how can i change my feeling of being worthless to everyone ?\"\\r\\n    ],\\r\\n    \"responses\": [\\r\\n      \"maybe lower your expectations for a bit\",\\r\\n      \"if you are whole - heartedly committed to moving past the sexual and romantic parts of your relationship and just having a friendship than refraining from all the touching would be a good place to start\",\\r\\n      \"very often , one person wants to deal with the conflict right away or shortly thereafter and the other person wants to wait\",\\r\\n      \"\\\\\" my best guess is that your boyfriend is triggered by some previous relationship , either romantic or in childhood\",\\r\\n      \"can he do that for you\",\\r\\n      \"\\\\\" friend \\\\\" is a broad category\",\\r\\n      \"in general , i usually let the client decide when this should occur , sometimes with some clients it will be a joint agreement , but even in that case it should weigh mostly on what the client feels\",\\r\\n      \"who takes care of your son , is a significant part of getting over your heartbreak\",\\r\\n      \"if everyone thinks you \\' re worthless , then maybe you need to find new people to hang out with . seriously , the social context in which a person lives is a big influence in self - esteem . otherwise , you can go round and round trying to understand why you \\' re not worthless , then go back to the same crowd and be knocked down again . there are many inspirational messages you can find in social media . maybe read some of the ones which state that no person is worthless , and that everyone has a good purpose to their life . also , since our culture is so saturated with the belief that if someone doesn \\' t feel good about themselves that this is somehow terrible . bad feelings are part of living . they are the motivation to remove ourselves from situations and relationships which do us more harm than good . bad feelings do feel terrible . your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today .\"\\r\\n      \\r\\n    ],\\r\\n    \"context_set\": \"\"\\r\\n  },\\r\\n\\r\\n    { \"tag\":\"issues\",\\r\\n       \\r\\n        \"patterns\": [\\r\\n          \"do i have too many issues for counseling ? i have so many issues to address . i have a patterns of sexual abuse , i ’ m a breast cancer survivor and i am a lifetime insomniac . i have a long patterns of depression and i ’ m beginning to have anxiety . i have low self esteem but i ’ ve been happily married for almost 35 years . i ’ ve never had counseling about any of this . do i have too many issues to address in counseling ?\"\\r\\n        ],\\r\\n        \"responses\": [\\r\\n          \"iitap\",\\r\\n          \"if your wife overheard the comment not knowing your intentions or context , it is possible that she may have misinterpreted what you have said\",\\r\\n          \"its always good to be very clear with oneself of what is the ultimate target here\",\\r\\n          \"concentrate on your own life and making your life the best it can be\",\\r\\n          \"if you feel yourself becoming heated , excuse yourself from the situation , go to a quiet place or on a walk , and practice some deep breathing\",\\r\\n          \"you get the worst because they trust your love\",\\r\\n          \"the best way for someone to understand us or to understand someone , is to directly talk about the specific problem\",\\r\\n          \"hold onto the likelihood that some day , they will come back and be grateful\",\\r\\n          \"let me start by saying there are never too many concerns that you can bring into counselling . in fact , most people who come to see me for counselling have more than one issue they would like to work on in psychotherapy and most times these are all interconnected . in counselling , we work together , collaboratively , to figure out which issues you would like to address first and then together we develop an individualized plan of care . basically , it ’ s like a road map of where you want to go , how are you going to get there , looking at stopovers , some scenic routes others possibly not so scenic , however , necessary . of course , these plans can also change due to internal ( what we have control over like our thoughts , feelings and behaviours ) or external reasons ( those things that are outside our control ) . i would encourage you to take the next step and reach out to a professional you can trust and build rapport with by co - journeying through whatever concerns you have by examining what has been working so far as you have learned to cope with some of your issues like insomnia , depression and anxiety , as well as being a breast cancer survivor . then to help you by developing new coping strategies . psychotherapy\"\\r\\n        ],\\r\\n        \"context_set\": \"\"\\r\\n      },\\r\\n\\r\\n      {\"tag\":\"anxiety\",\\r\\n            \"patterns\": [\\r\\n              \"how do i find out the cause of my depression and anxiety ? i have been feeling more and more down for over a month . i have started having trouble sleeping due to panic attacks , but they are almost never triggered by something that i know of .\"\\r\\n            ],\\r\\n            \"responses\": [\\r\\n              \"also , its possible your friends already have questioned why you wore a bigger bra than your boobs\",\\r\\n              \"sticking to a system which mirrors the type of person you are , means more than any one particular answer anyone gives you\",\\r\\n              \"however , it is what it is\",\\r\\n              \"someone working with the school ( usually a school psychologist ) should be able to evaluate her to see if she needs extra help and to tell you more clearly what may be happening\",\\r\\n              \"what a tough situation you must be in , feeling torn between your parents and someone who is very special to you\",\\r\\n              \"this may result in bringing the two of you closer and taking the relationship to the next level\",\\r\\n              \"do you want your marriage\",\\r\\n              \"in the best case scenario the decision to move on from therapy and “ say our goodbyes ” happens when both the therapist and the client feel like the client is ready to move on and move up\",\\r\\n              \"answers about our inner lives are most successfully reached from a sense of feeling grounded in oneself . first step is to accept your nervousness and restless sleep . as often as possible , sleep during daytimes in order for your body to catch up on its need for rest . accept too about feeling down . it is normal to feel down once in a while . from this place of self - acceptance , trust any answers which come up to your mind . often answers about complicated topics come in small pieces , not all at once as a whole unit . also , your description about panic attacks is also completely normal . they often arise unrelated to particular conditions at a given moment . they are a healthy symptom your body is trying to expel bad feelings and does this by having the anxiety erupt at times . so , self - acceptance , tolerance of being on a process of clearing out worn out emotional clutter , and sleep at odd times if possible , are all ways to stabilize yourself , which will also feel calm and good !\"\\r\\n            ],\\r\\n            \"context_set\": \"\"\\r\\n          },\\r\\n          {\"tag\":\"depression\",\\r\\n\\r\\n                \"patterns\": [\\r\\n                  \"how do i overcome my anxierty and depression ? i ’ m facing severe depression and anxiety and i just feel like i ’ m going through a lot . this really distracts me and i cant get my mind off the things that are bothering me . how do i overcome this anxierty and depression ?\"\\r\\n                ],\\r\\n                \"responses\": [\\r\\n                  \"it would be impossible to satisfy all of those expectations for every single person in our lives\",\\r\\n                  \"a good start is to pay attention to some basic issues : sleep , nutrition , exercise and socially supportive relationships\",\\r\\n                  \"it may , initially feel this way after a breakup\",\\r\\n                  \"i am not sure if you received counseling after what happened to you , but that may be something to consider\",\\r\\n                  \"but usually , things like what you describe your dad is doing are not considered to be child abuse\",\\r\\n                  \"but what makes friendships special is that they last trough time , at least with those who we call our true friends , those who know us well and whom we have a special connection and those from whom we disconnect at times , without fear of losing them\",\\r\\n                  \"is the message being sent coming from a place of love or concern\",\\r\\n                  \"it may , initially feel this way after a breakup\",\\r\\n                  \"have you used meditation or hypnosis ? relaxing the mind and connecting with your true self is a great way to calm your thoughts and get to peace and calm . hypnosis and meditation have helped a lot of people with anxiety and depression . google hypnotherapists near me or write for a while about what is going on .\"\\r\\n                ],\\r\\n                \"context_set\": \"\"\\r\\n              },\\r\\n              { \\r\\n                \"tag\":\"upset\",\\r\\n                 \"patterns\": [\\r\\n                      \"why am i upset or down every day even when nothing is going on ? how can i get to a place where i can be content from day to day ?\"\\r\\n                    ],\\r\\n                    \"responses\": [\\r\\n                      \"can you see that underneath the nagging there \\' s a pretty overwhelmed and powerless person who needs assistance\",\\r\\n                      \": ) i will not say that you can \\' t but i will say it will be much harder and the time may take much longer\",\\r\\n                      \"thank you for asking this important question\",\\r\\n                      \"you want respect\",\\r\\n                      \"a relationship gets weaker , not stronger by threatening control of the other person\",\\r\\n                      \"if you can see her responses as habits , rather than a reflection of how she feels about you , then you can keep yourself calm\",\\r\\n                      \"this is not stupid , this is your mind telling you that there is something that needs to be worked through\",\\r\\n                      \"wouldn \\' t it not be best to go to those around you that do provide comfort and aid , first\",\\r\\n                      \"your question is a fascinating one ! as humans we have the ability to reflect on situations in our lives . even if nothing currently goes on in a particular moment , it ’ s possible you ’ re reflecting on a serious or upsetting matter . and , our emotions linger within us . just because a particular moment feels calm , inside your feelings may be the sense of a strong unsettled emotion from the recent past . good for you to be aware of your own sensitivity to living with awareness of your moods and thoughts .\"\\r\\n                    ],\\r\\n                    \"context_set\": \"\"\\r\\n                  },\\r\\n                  {\\r\\n                    \\r\\n                    \"tag\":\"pain\",\\r\\n                        \"patterns\": [\\r\\n                          \"how can i deal with depression stemming from chronic pain ? i have a severe back problem . i \\' ve had 3 major and several minor operations , but i \\' m still in constant pain . how can i deal with the depression from this chronic pain ?\"\\r\\n                        ],\\r\\n                        \"responses\": [\\r\\n                          \"the person would guide you in working with the dog to become calmer\",\\r\\n                          \"because you have the awareness that you do , i feel this is a very good sign that with treatment you can live a normal life ( assuming you are not already receiving treatment for it\",\\r\\n                          \"this isn \\' t something you can do on your own\",\\r\\n                          \"some medicines may have that side effect as well\",\\r\\n                          \"la relacion de consejeria tambien puede terminar por no conformar o violentar los parametros establecidos para la terapia\",\\r\\n                          \"i wish you well\",\\r\\n                          \"are you seeing a therapist or attending any therapeutic or supportive group\",\\r\\n                          \"once the therapy goals have been met , there is a closing session , the counseling relationship is ended , and the client can stop attending sessions\",\\r\\n                          \"chronic pain at the back likely results from a few areas : l4 - l5 kidney zone , most likely ( lower back ) ; bone spurs , fused discs , and slipped discs , caused by connective tissue weakness , and calcium deposits used to neutralize highly acidic areas . . . the \\' depression \\' will evaporate when the chronic pain is drained out , through natural means ; pharmaceutical means will simply extend the pain and cause it to deepen over time , not solving the problem ; remember , medical doctors suppress , natural doctors cure . . .\"\\r\\n                        ],\\r\\n                        \"context_set\": \"\"\\r\\n                      },\\r\\n                      {\\r\\n                        \"tag\":\"failure\",\\r\\n                            \"patterns\": [\\r\\n                              \"how can i get counseling if my primary care physician won \\' t help ? i suffer from adult adhd , anxiety disorder , and depression . it has been difficult to find a doctor in my area and my primary physician won \\' t help . i am unemployed and overwhelmed . what would you suggest i do ?\"\\r\\n                            ],\\r\\n                            \"responses\": [\\r\\n                              \"after reading your question , i wondered how you went from \\\\\" making out \\\\\" to \\\\\" nothing happened\",\\r\\n                              \"¿ como trabajo con un esposo que solo contribuye economicamente\",\\r\\n                              \"the paradox of thinking about forever is that you can become more motivated to live only in the present\",\\r\\n                              \"you \\' re expecting reasonable behaviors from your boyfriend \\' s father\",\\r\\n                              \"muchas veces cuando los papas estan afuera las mamas desarrollan rutinas que luego ellos no quieren interrumpir\",\\r\\n                              \"not everyone who experiences a car accident develops ptsd\",\\r\\n                              \"¿ deberia hacer algo al respecto\",\\r\\n                              \"in the long term , knowing you are getting what you want and at the very least stating your expectations to your boyfriend , will clarify for him , what is meaningful in your relationship\",\\r\\n                              \"if it is simply counseling that you seek , any number of faith - based outfits are very willing to listen and help out with these sorts of matters , free of charge : ) online messaging and social media is a secondary option , however this one may come with privacy concerns and consequences ; if it were i , i would attempt to sweet - talk one or two counselors i come across to do a bit of work for folks who can \\' t afford it : )\"\\r\\n                            ],\\r\\n                            \"context_set\": \"\"\\r\\n                          },\\r\\n                          {\\r\\n                            \"tag\":\"Sex\",\\r\\n                                \"patterns\": [\\r\\n                                  \"why am i experiencing dfficulty maintaining an erection ? a few years ago i was making love to my wife when for no known reason i lost my erection , now i \\' m in my early 30s and my problem has become more and more frequent . this is causing major problems for my ego and it \\' s diminishing my self esteem . this has resulted in ongoing depression and tearing apart my marriage . i am devastated and cannot find a cause for these issues . i am very attracted to my wife and want to express it in the bedroom like i used to . what could be causing this , and what can i do about it ?\"\\r\\n                                ],\\r\\n                                \"responses\": [\\r\\n                                  \"certain foods are linked with poor sleep\",\\r\\n                                  \"there are resources out there - people to talk to\",\\r\\n                                  \"employers can be held responsible if they do not take action\",\\r\\n                                  \"allow yourself to withdraw when situations feel dangerous\",\\r\\n                                  \"then , allow some time so each of you is clear about their own expectations and what is possible to offer the other\",\\r\\n                                  \"you could try having a conversation when you \\' re not fighting and starting it out by saying that you would like to discuss something important to you and see if your fiancee is open to that\",\\r\\n                                  \"staying present is an attitude most of us aspire to , and most of us have to work at it — certainly at first\",\\r\\n                                  \"have you talked to a therapist\",\\r\\n                                  \"first step always is to do a medical rule out so that you \\' re sure the problem is psychological and emotion based , not a medical condition which requires care and attention . if you are medically clear in the reasons for losing your erection , then reflect on what may be creating a loss in confidence in either who you are and what you \\' re doing with your life , or whether your wife has these sort of problems within herself . often a problem transfers ownership of who shows it . if you are a sensitive person its possible your erection problem reflects your wife \\' s insecurities and self - doubt . if she is someone who is reluctant to talk about feeling unsure then in a certain way by you showing a problem , she can avoid looking at herself . there may not be a direct cause such as usually exists in a medical problem . medicine looks for symptoms to treat . our emotional lives are much more indirect . if you feel stress at work or are unhappy in the place you live , for example , then your frustration may show up in your sex life . basically , do a broad inward search of your life and what it holds and maybe ask your wife to do the same . you may clear the air within yourselves and between each other so the problem goes away .\"\\r\\n                                ],\\r\\n                                \"context_set\": \"\"\\r\\n                              },\\r\\n                              {\\r\\n                                \"tag\":\"stuck\",\\r\\n                                    \"patterns\": [\\r\\n                                      \"how do depression and pms symptoms contribute to one another and what can i do about it ? i struggle with depression as well as pretty intense mood swings throughout the month . i experience highs where i feel amazing and energetic and then lows where i lack focus , energy , and generally have a more dark outlook on my life . how can i live a more balanced life ?\"\\r\\n                                    ],\\r\\n                                    \"responses\": [\\r\\n                                      \"i have worked with the lesbian , gay , bisexual , transgender , queer ( lgbtq ) community in various ways over the years\",\\r\\n                                      \", lmhc hi , this sounds like a very challenging and upsetting problem - good for you for reaching out\",\\r\\n                                      \"i hope this helps you , your family members , and the pets\",\\r\\n                                      \"you are not crazy or insane for thinking of working with a counselor , nor of having feelings of same sex attraction\",\\r\\n                                      \"there is no correct number of topics\",\\r\\n                                      \"examine the basics of your growing up years and what may explain why you feel insecure\",\\r\\n                                      \"anxiety is overwhelming insecurity\",\\r\\n                                      \"very often kids who are not encouraged to try new activities , have fun in relating to others , learn to not trust themselves to handle these fundamental parts of life\",\\r\\n                                      \"it \\' s fun to ride the roller coaster from time to time , isn \\' t it ? : ) but , it \\' s also weary - making , and leads to drainage that no man or woman can hardly anticipate ! balance comes with proper understanding of the different bodies you possess and how they function . and , to begin , we focus upon your physical , and move right up the latter to the spiritual , and begin cleaning you out . unbalance is an experience of blocked energies that should be naturally flowing ( call them what thou mayest ) ; when blockages are removed , what is naturally there flows , and flows beautifully . . .\"\\r\\n                                    \\r\\n                                    ],\\r\\n                                    \"context_set\": \"\"\\r\\n                                  },\\r\\n                                  {\"tag\":\"help\",\\r\\n                                    \\r\\n                                        \"patterns\": [\\r\\n                                          \"how can i get my husband to listen to my needs and talk to me ? i tried telling my husband i was depressed , and he ignored me . he said \\\\\" you \\' re always sad or depressed . \\\\\" and he picked up his phone and ignored me . i said , \\\\\" please don \\' t exaggerate , that isn \\' t true . \\\\\" and he said , \\\\\" whatever babe . you just want to be sad . \\\\\" how can i get through to him so he will take me seriously ?\"\\r\\n                                        ],\\r\\n                                        \"responses\": [\\r\\n                                          \"also try restating what your husband is saying to make sure that you are understanding correctly\",\\r\\n                                          \"i am so sorry that this happened\",\\r\\n                                          \"also in the initial conversation , you can feel free to ask what their therapeutic modality is or give a brief scenario and ask how the therapist might respond to that situation\",\\r\\n                                          \"if what he is telling you is different than what you have heard or thought of for many years , it may be challenging to follow his meaning initially\",\\r\\n                                          \"eventually , stability and peace of mind return , and being alone with oneself is preferred to being taken on an emotional rollercoaster by a partner\",\\r\\n                                          \"it is absolutely normal to be nervous about therapy\",\\r\\n                                          \"i am less concerned about this man as bisexual and having gay friends , than about how you feel is treating you\",\\r\\n                                          \"choosing the right therapist can sometimes feel a bit overwhelming\",\\r\\n                                          \"ouch . it \\' s really hard to deal with a spouse that isn \\' t taking you seriously . in this case , i would plan for and schedule a time to talk with him about this . i would tell him that you need about 30 minutes to talk to him with minimal interruptions about something that is important to you . schedule a time , write notes if you need reminders about what you need to express , and tell him how you feel . ideally , you would focus more on i - statements instead of telling him what he is doing wrong . for example , i feel ignored vs you always ignore me . by focusing on how you feel , he is less likely to feel attacked and get defensive . some people go to couples or marriage counseling for help with communication . chances are there are things that both of you do that hurts your communication . overall , try to talk to him directly and try not to get defensive . if he continues to say , you \\' re always sad - then stay calm , say \\\\\" okay , can you help me understand that more ? \\\\\" or \\\\\" that \\' s interesting . tell me what you see . \\\\\" reach out to a couples counselor for more help with communication strategies . sometimes a 3rd party can help you both see things in a\"\\r\\n                                        ]\\r\\n                                      },\\r\\n                                      { \"tag\":\"why\",\\r\\n                                        \\r\\n                                            \"patterns\": [\\r\\n                                              \"why do i crave depression ? it \\' s not entirely true to say i enjoy being sad , but i always find a way to feel that way . i listen to sad music , read tragic stories , and , in a twisted way , like how bad it makes me feel . i focus on negative aspects of my life even if they aren \\' t legitimate or i just make it seem negative .\"\\r\\n                                            ],\\r\\n                                            \"responses\": [\\r\\n                                              \"if you find yourself arguing with your mom , stop\",\\r\\n                                              \"it may also be helpful to make a list of your concerns or fears about being away from your family\",\\r\\n                                              \"i believe that for results that last , the best approach is to understand why someone feels like doing a certain behavior\",\\r\\n                                              \"a good spouse sacrifices their needs to see the other person happy\",\\r\\n                                              \"i would encourage you to look for a trauma therapist who offers a sliding scale or pro bono services\",\\r\\n                                              \"\\\\\" \\\\\" you don \\' t\",\\r\\n                                              \"since you don \\' t know what to do , then for right now postpone your wedding date\",\\r\\n                                              \"let me first say that i am sorry you are going through this\",\\r\\n                                              \"it sounds like you are noticing that you are drawn towards sad and negative content and it \\' s hard to understand why . this may sound counter - intuitive , but sometimes we do things that on the surface may look problematic ( or even cause us some real problems ) because it serves us in some unseen way . a simple example would be somebody who is addicted to a substance ; their addiction may be causing serious problems in their life , and they may even know it , but the addiction serves them by helping them to avoid painful feelings that they anticipate having if they quit using . now i am not saying that what you describe is an addiction , it is just a really illustrative example of the unseen benefit . one thing i would be wondering about is what is the unseen benefit of seeking out sad and negative content ? i \\' d also be wondering what your relationship is to other feelings . these are things you may benefit from exploring with a competent therapist .\"\\r\\n                                            ],\\r\\n                                            \"context_set\": \"\"\\r\\n                                          },\\r\\n                                          {\\r\\n                                            \"tag\":\"heal\",\\r\\n                                                \"patterns\": [\\r\\n                                                  \"i \\' m seriously unhappy with everything in my life but i know i don \\' t have any reason to feel this way i can \\' t even smile or fake one . i can \\' t feel happiness about anything and i can \\' t show love towards another person not even my girlfriend . i hate myself sometimes . all i see is ugly . i can \\' t get over the loss of a loved one and i \\' m not close to my family . what can i do ?\"\\r\\n                                                ],\\r\\n                                                \"responses\": [\\r\\n                                                  \"the problem is how long you \\' re holding it in your hand\",\\r\\n                                                  \"i wish you the best\",\\r\\n                                                  \"what would the worst part be\",\\r\\n                                                  \"part of the therapy process is to look at your feelings , and to feel what you are actually feeling ( instead of what you think you should feel )\",\\r\\n                                                  \"we call these \\\\\" comorbid \\\\\" conditions , which means that two or more mental health problems exist at one time\",\\r\\n                                                  \"you deserve the help just as much as anyone else\",\\r\\n                                                  \"in fact , all of what you described points to the importance of you seeking help in order to cope with the many challenges in your life\",\\r\\n                                                  \"heck , sure thing , hun\",\\r\\n                                                  \"trust and believe your own feelings . emotions are real and reflect how someone feels about a situation . since you \\' re sad about losing a loved one , be patient w your feelings about this . basically , be guided by how you feel and eventually you will feel different emotions which i hope will be happier ones .\"\\r\\n                                                ],\\r\\n                                                \"context_set\": \"\"\\r\\n                                              },\\r\\n                                              {\\r\\n                                                \"tag\":\"Solution\",\\r\\n                                                \\r\\n                                                    \"patterns\": [\\r\\n                                                      \"is there anything i can do about my depression and anxiety ? i have been dealing with depression and anxiety for a number of years . i have been on medication , but lately my depression has felt worse . can counseling help ?\"\\r\\n                                                    ],\\r\\n                                                    \"responses\": [\\r\\n                                                      \"being a parent can be all - consuming\",\\r\\n                                                      \"if you have difficulty initiating self - care routine talk to your therapist about what motivates you and pushes you to do things , you might find the key during the process\",\\r\\n                                                      \"hi anaheim , relationships with therapists have some things in common with other relationships ; they work best if there is dialogue about what your hopes , thoughts , emotions and needs are\",\\r\\n                                                      \"hi bethlehem , you have a big decision to make\",\\r\\n                                                      \"breath in and out of that space\",\\r\\n                                                      \"you could also contact your physician or a psychiatrist to discuss medication options if it ’ s too challenging to begin basic self - care\",\\r\\n                                                      \"if not that , ive sometimes encouraged folk to just leave some information on depression and how family can help like a pamphlet or handout on a table or around the house\",\\r\\n                                                      \"when to seek professional help\",\\r\\n                                                      \"thank you for asking this important question . i find that there are three steps to getting ready for treatment . step one is expressing interest in wanting to receiving treatment for the outcome of positive behavioral change . congratulations you did the first step ! you are showing your readiness to start counseling by asking this question . now the second step is to find a counselor who specializes in treating clients with anxiety and depression . the therapeutic orientations i have found to be helpful in treating clients with anxiety and depression are a combination of cognitive behavioral therapy with mindfulness , and solution focused brief therapy . receiving meditation for your symptoms if part of the treatment , and the other part is receiving counseling to increase your resilience for future events . research has found that medication and psychotherapy treatments together shows the most effective outcome for depression . the third step is to increase your positive self - talk to motivate yourself to attend treatment . as counselors , we are aware of the anxieties and fears that are associated with talking to a new professional for the first time . however , remind yourself that you are doing this to improve your well being . i hope this was helpful , and good luck with your treatment journey .\"\\r\\n                                                    \\r\\n                                                    \\r\\n                                                    ],\\r\\n                                                    \"context_set\": \"\"\\r\\n                                                  }\\r\\n                                                \\r\\n                                                ]\\r\\n                                            }\\r\\n\\r\\n                                            \\r\\n                                        \\r\\n                                    \\r\\n                                  \\r\\n                                          \\r\\n                                            \\r\\n                                                                      \\r\\n                                    \\r\\n                          \\r\\n                        \\r\\n                      \\r\\n                    \\r\\n                  \\r\\n                \\r\\n              \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n    \\r\\n  \\r\\n\\r\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8swdGpk6-Qd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "721GJjs35kqT",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPh-RR5tlJyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import codecs\n",
        "\n",
        "data=json.load(codecs.open('ashap.json', 'r', 'utf-8-sig'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygQrNyxKoCgs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "91c98707-cd40-4247-ea89-e4712eab87ea"
      },
      "source": [
        "data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intents': [{'context_set': '',\n",
              "   'patterns': ['Hi',\n",
              "    'How are you',\n",
              "    'Is anyone there?',\n",
              "    'Hello',\n",
              "    'Good day',\n",
              "    'Whats up'],\n",
              "   'responses': ['Hi there, how can I help?'],\n",
              "   'tag': 'greeting'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['cya',\n",
              "    'See you later',\n",
              "    'Goodbye',\n",
              "    'I am Leaving',\n",
              "    'Have a Good day'],\n",
              "   'responses': ['Sad to see you go :(',\n",
              "    'Talk to you later',\n",
              "    'Goodbye!,I hope I helped you feel better in anyway :)'],\n",
              "   'tag': 'goodbye'},\n",
              "  {'context_set': '',\n",
              "   'patterns': [\"can i change my feeling of being worthless to everyone ? i ' m going through some things with my feelings and myself . i barely sleep and i do nothing but think about how i ' m worthless and how i shouldn ' t be here . i ' ve never tried or contemplated suicide . i ' ve always wanted to fix my issues , but i never get around to it . how can i change my feeling of being worthless to everyone ?\"],\n",
              "   'responses': ['maybe lower your expectations for a bit',\n",
              "    'if you are whole - heartedly committed to moving past the sexual and romantic parts of your relationship and just having a friendship than refraining from all the touching would be a good place to start',\n",
              "    'very often , one person wants to deal with the conflict right away or shortly thereafter and the other person wants to wait',\n",
              "    '\" my best guess is that your boyfriend is triggered by some previous relationship , either romantic or in childhood',\n",
              "    'can he do that for you',\n",
              "    '\" friend \" is a broad category',\n",
              "    'in general , i usually let the client decide when this should occur , sometimes with some clients it will be a joint agreement , but even in that case it should weigh mostly on what the client feels',\n",
              "    'who takes care of your son , is a significant part of getting over your heartbreak',\n",
              "    \"if everyone thinks you ' re worthless , then maybe you need to find new people to hang out with . seriously , the social context in which a person lives is a big influence in self - esteem . otherwise , you can go round and round trying to understand why you ' re not worthless , then go back to the same crowd and be knocked down again . there are many inspirational messages you can find in social media . maybe read some of the ones which state that no person is worthless , and that everyone has a good purpose to their life . also , since our culture is so saturated with the belief that if someone doesn ' t feel good about themselves that this is somehow terrible . bad feelings are part of living . they are the motivation to remove ourselves from situations and relationships which do us more harm than good . bad feelings do feel terrible . your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today .\"],\n",
              "   'tag': 'Suicide'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['do i have too many issues for counseling ? i have so many issues to address . i have a patterns of sexual abuse , i ’ m a breast cancer survivor and i am a lifetime insomniac . i have a long patterns of depression and i ’ m beginning to have anxiety . i have low self esteem but i ’ ve been happily married for almost 35 years . i ’ ve never had counseling about any of this . do i have too many issues to address in counseling ?'],\n",
              "   'responses': ['iitap',\n",
              "    'if your wife overheard the comment not knowing your intentions or context , it is possible that she may have misinterpreted what you have said',\n",
              "    'its always good to be very clear with oneself of what is the ultimate target here',\n",
              "    'concentrate on your own life and making your life the best it can be',\n",
              "    'if you feel yourself becoming heated , excuse yourself from the situation , go to a quiet place or on a walk , and practice some deep breathing',\n",
              "    'you get the worst because they trust your love',\n",
              "    'the best way for someone to understand us or to understand someone , is to directly talk about the specific problem',\n",
              "    'hold onto the likelihood that some day , they will come back and be grateful',\n",
              "    'let me start by saying there are never too many concerns that you can bring into counselling . in fact , most people who come to see me for counselling have more than one issue they would like to work on in psychotherapy and most times these are all interconnected . in counselling , we work together , collaboratively , to figure out which issues you would like to address first and then together we develop an individualized plan of care . basically , it ’ s like a road map of where you want to go , how are you going to get there , looking at stopovers , some scenic routes others possibly not so scenic , however , necessary . of course , these plans can also change due to internal ( what we have control over like our thoughts , feelings and behaviours ) or external reasons ( those things that are outside our control ) . i would encourage you to take the next step and reach out to a professional you can trust and build rapport with by co - journeying through whatever concerns you have by examining what has been working so far as you have learned to cope with some of your issues like insomnia , depression and anxiety , as well as being a breast cancer survivor . then to help you by developing new coping strategies . psychotherapy'],\n",
              "   'tag': 'issues'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['how do i find out the cause of my depression and anxiety ? i have been feeling more and more down for over a month . i have started having trouble sleeping due to panic attacks , but they are almost never triggered by something that i know of .'],\n",
              "   'responses': ['also , its possible your friends already have questioned why you wore a bigger bra than your boobs',\n",
              "    'sticking to a system which mirrors the type of person you are , means more than any one particular answer anyone gives you',\n",
              "    'however , it is what it is',\n",
              "    'someone working with the school ( usually a school psychologist ) should be able to evaluate her to see if she needs extra help and to tell you more clearly what may be happening',\n",
              "    'what a tough situation you must be in , feeling torn between your parents and someone who is very special to you',\n",
              "    'this may result in bringing the two of you closer and taking the relationship to the next level',\n",
              "    'do you want your marriage',\n",
              "    'in the best case scenario the decision to move on from therapy and “ say our goodbyes ” happens when both the therapist and the client feel like the client is ready to move on and move up',\n",
              "    'answers about our inner lives are most successfully reached from a sense of feeling grounded in oneself . first step is to accept your nervousness and restless sleep . as often as possible , sleep during daytimes in order for your body to catch up on its need for rest . accept too about feeling down . it is normal to feel down once in a while . from this place of self - acceptance , trust any answers which come up to your mind . often answers about complicated topics come in small pieces , not all at once as a whole unit . also , your description about panic attacks is also completely normal . they often arise unrelated to particular conditions at a given moment . they are a healthy symptom your body is trying to expel bad feelings and does this by having the anxiety erupt at times . so , self - acceptance , tolerance of being on a process of clearing out worn out emotional clutter , and sleep at odd times if possible , are all ways to stabilize yourself , which will also feel calm and good !'],\n",
              "   'tag': 'anxiety'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['how do i overcome my anxierty and depression ? i ’ m facing severe depression and anxiety and i just feel like i ’ m going through a lot . this really distracts me and i cant get my mind off the things that are bothering me . how do i overcome this anxierty and depression ?'],\n",
              "   'responses': ['it would be impossible to satisfy all of those expectations for every single person in our lives',\n",
              "    'a good start is to pay attention to some basic issues : sleep , nutrition , exercise and socially supportive relationships',\n",
              "    'it may , initially feel this way after a breakup',\n",
              "    'i am not sure if you received counseling after what happened to you , but that may be something to consider',\n",
              "    'but usually , things like what you describe your dad is doing are not considered to be child abuse',\n",
              "    'but what makes friendships special is that they last trough time , at least with those who we call our true friends , those who know us well and whom we have a special connection and those from whom we disconnect at times , without fear of losing them',\n",
              "    'is the message being sent coming from a place of love or concern',\n",
              "    'it may , initially feel this way after a breakup',\n",
              "    'have you used meditation or hypnosis ? relaxing the mind and connecting with your true self is a great way to calm your thoughts and get to peace and calm . hypnosis and meditation have helped a lot of people with anxiety and depression . google hypnotherapists near me or write for a while about what is going on .'],\n",
              "   'tag': 'depression'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['why am i upset or down every day even when nothing is going on ? how can i get to a place where i can be content from day to day ?'],\n",
              "   'responses': [\"can you see that underneath the nagging there ' s a pretty overwhelmed and powerless person who needs assistance\",\n",
              "    \": ) i will not say that you can ' t but i will say it will be much harder and the time may take much longer\",\n",
              "    'thank you for asking this important question',\n",
              "    'you want respect',\n",
              "    'a relationship gets weaker , not stronger by threatening control of the other person',\n",
              "    'if you can see her responses as habits , rather than a reflection of how she feels about you , then you can keep yourself calm',\n",
              "    'this is not stupid , this is your mind telling you that there is something that needs to be worked through',\n",
              "    \"wouldn ' t it not be best to go to those around you that do provide comfort and aid , first\",\n",
              "    'your question is a fascinating one ! as humans we have the ability to reflect on situations in our lives . even if nothing currently goes on in a particular moment , it ’ s possible you ’ re reflecting on a serious or upsetting matter . and , our emotions linger within us . just because a particular moment feels calm , inside your feelings may be the sense of a strong unsettled emotion from the recent past . good for you to be aware of your own sensitivity to living with awareness of your moods and thoughts .'],\n",
              "   'tag': 'upset'},\n",
              "  {'context_set': '',\n",
              "   'patterns': [\"how can i deal with depression stemming from chronic pain ? i have a severe back problem . i ' ve had 3 major and several minor operations , but i ' m still in constant pain . how can i deal with the depression from this chronic pain ?\"],\n",
              "   'responses': ['the person would guide you in working with the dog to become calmer',\n",
              "    'because you have the awareness that you do , i feel this is a very good sign that with treatment you can live a normal life ( assuming you are not already receiving treatment for it',\n",
              "    \"this isn ' t something you can do on your own\",\n",
              "    'some medicines may have that side effect as well',\n",
              "    'la relacion de consejeria tambien puede terminar por no conformar o violentar los parametros establecidos para la terapia',\n",
              "    'i wish you well',\n",
              "    'are you seeing a therapist or attending any therapeutic or supportive group',\n",
              "    'once the therapy goals have been met , there is a closing session , the counseling relationship is ended , and the client can stop attending sessions',\n",
              "    \"chronic pain at the back likely results from a few areas : l4 - l5 kidney zone , most likely ( lower back ) ; bone spurs , fused discs , and slipped discs , caused by connective tissue weakness , and calcium deposits used to neutralize highly acidic areas . . . the ' depression ' will evaporate when the chronic pain is drained out , through natural means ; pharmaceutical means will simply extend the pain and cause it to deepen over time , not solving the problem ; remember , medical doctors suppress , natural doctors cure . . .\"],\n",
              "   'tag': 'pain'},\n",
              "  {'context_set': '',\n",
              "   'patterns': [\"how can i get counseling if my primary care physician won ' t help ? i suffer from adult adhd , anxiety disorder , and depression . it has been difficult to find a doctor in my area and my primary physician won ' t help . i am unemployed and overwhelmed . what would you suggest i do ?\"],\n",
              "   'responses': ['after reading your question , i wondered how you went from \" making out \" to \" nothing happened',\n",
              "    '¿ como trabajo con un esposo que solo contribuye economicamente',\n",
              "    'the paradox of thinking about forever is that you can become more motivated to live only in the present',\n",
              "    \"you ' re expecting reasonable behaviors from your boyfriend ' s father\",\n",
              "    'muchas veces cuando los papas estan afuera las mamas desarrollan rutinas que luego ellos no quieren interrumpir',\n",
              "    'not everyone who experiences a car accident develops ptsd',\n",
              "    '¿ deberia hacer algo al respecto',\n",
              "    'in the long term , knowing you are getting what you want and at the very least stating your expectations to your boyfriend , will clarify for him , what is meaningful in your relationship',\n",
              "    \"if it is simply counseling that you seek , any number of faith - based outfits are very willing to listen and help out with these sorts of matters , free of charge : ) online messaging and social media is a secondary option , however this one may come with privacy concerns and consequences ; if it were i , i would attempt to sweet - talk one or two counselors i come across to do a bit of work for folks who can ' t afford it : )\"],\n",
              "   'tag': 'failure'},\n",
              "  {'context_set': '',\n",
              "   'patterns': [\"why am i experiencing dfficulty maintaining an erection ? a few years ago i was making love to my wife when for no known reason i lost my erection , now i ' m in my early 30s and my problem has become more and more frequent . this is causing major problems for my ego and it ' s diminishing my self esteem . this has resulted in ongoing depression and tearing apart my marriage . i am devastated and cannot find a cause for these issues . i am very attracted to my wife and want to express it in the bedroom like i used to . what could be causing this , and what can i do about it ?\"],\n",
              "   'responses': ['certain foods are linked with poor sleep',\n",
              "    'there are resources out there - people to talk to',\n",
              "    'employers can be held responsible if they do not take action',\n",
              "    'allow yourself to withdraw when situations feel dangerous',\n",
              "    'then , allow some time so each of you is clear about their own expectations and what is possible to offer the other',\n",
              "    \"you could try having a conversation when you ' re not fighting and starting it out by saying that you would like to discuss something important to you and see if your fiancee is open to that\",\n",
              "    'staying present is an attitude most of us aspire to , and most of us have to work at it — certainly at first',\n",
              "    'have you talked to a therapist',\n",
              "    \"first step always is to do a medical rule out so that you ' re sure the problem is psychological and emotion based , not a medical condition which requires care and attention . if you are medically clear in the reasons for losing your erection , then reflect on what may be creating a loss in confidence in either who you are and what you ' re doing with your life , or whether your wife has these sort of problems within herself . often a problem transfers ownership of who shows it . if you are a sensitive person its possible your erection problem reflects your wife ' s insecurities and self - doubt . if she is someone who is reluctant to talk about feeling unsure then in a certain way by you showing a problem , she can avoid looking at herself . there may not be a direct cause such as usually exists in a medical problem . medicine looks for symptoms to treat . our emotional lives are much more indirect . if you feel stress at work or are unhappy in the place you live , for example , then your frustration may show up in your sex life . basically , do a broad inward search of your life and what it holds and maybe ask your wife to do the same . you may clear the air within yourselves and between each other so the problem goes away .\"],\n",
              "   'tag': 'Sex'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['how do depression and pms symptoms contribute to one another and what can i do about it ? i struggle with depression as well as pretty intense mood swings throughout the month . i experience highs where i feel amazing and energetic and then lows where i lack focus , energy , and generally have a more dark outlook on my life . how can i live a more balanced life ?'],\n",
              "   'responses': ['i have worked with the lesbian , gay , bisexual , transgender , queer ( lgbtq ) community in various ways over the years',\n",
              "    ', lmhc hi , this sounds like a very challenging and upsetting problem - good for you for reaching out',\n",
              "    'i hope this helps you , your family members , and the pets',\n",
              "    'you are not crazy or insane for thinking of working with a counselor , nor of having feelings of same sex attraction',\n",
              "    'there is no correct number of topics',\n",
              "    'examine the basics of your growing up years and what may explain why you feel insecure',\n",
              "    'anxiety is overwhelming insecurity',\n",
              "    'very often kids who are not encouraged to try new activities , have fun in relating to others , learn to not trust themselves to handle these fundamental parts of life',\n",
              "    \"it ' s fun to ride the roller coaster from time to time , isn ' t it ? : ) but , it ' s also weary - making , and leads to drainage that no man or woman can hardly anticipate ! balance comes with proper understanding of the different bodies you possess and how they function . and , to begin , we focus upon your physical , and move right up the latter to the spiritual , and begin cleaning you out . unbalance is an experience of blocked energies that should be naturally flowing ( call them what thou mayest ) ; when blockages are removed , what is naturally there flows , and flows beautifully . . .\"],\n",
              "   'tag': 'stuck'},\n",
              "  {'patterns': ['how can i get my husband to listen to my needs and talk to me ? i tried telling my husband i was depressed , and he ignored me . he said \" you \\' re always sad or depressed . \" and he picked up his phone and ignored me . i said , \" please don \\' t exaggerate , that isn \\' t true . \" and he said , \" whatever babe . you just want to be sad . \" how can i get through to him so he will take me seriously ?'],\n",
              "   'responses': ['also try restating what your husband is saying to make sure that you are understanding correctly',\n",
              "    'i am so sorry that this happened',\n",
              "    'also in the initial conversation , you can feel free to ask what their therapeutic modality is or give a brief scenario and ask how the therapist might respond to that situation',\n",
              "    'if what he is telling you is different than what you have heard or thought of for many years , it may be challenging to follow his meaning initially',\n",
              "    'eventually , stability and peace of mind return , and being alone with oneself is preferred to being taken on an emotional rollercoaster by a partner',\n",
              "    'it is absolutely normal to be nervous about therapy',\n",
              "    'i am less concerned about this man as bisexual and having gay friends , than about how you feel is treating you',\n",
              "    'choosing the right therapist can sometimes feel a bit overwhelming',\n",
              "    'ouch . it \\' s really hard to deal with a spouse that isn \\' t taking you seriously . in this case , i would plan for and schedule a time to talk with him about this . i would tell him that you need about 30 minutes to talk to him with minimal interruptions about something that is important to you . schedule a time , write notes if you need reminders about what you need to express , and tell him how you feel . ideally , you would focus more on i - statements instead of telling him what he is doing wrong . for example , i feel ignored vs you always ignore me . by focusing on how you feel , he is less likely to feel attacked and get defensive . some people go to couples or marriage counseling for help with communication . chances are there are things that both of you do that hurts your communication . overall , try to talk to him directly and try not to get defensive . if he continues to say , you \\' re always sad - then stay calm , say \" okay , can you help me understand that more ? \" or \" that \\' s interesting . tell me what you see . \" reach out to a couples counselor for more help with communication strategies . sometimes a 3rd party can help you both see things in a'],\n",
              "   'tag': 'help'},\n",
              "  {'context_set': '',\n",
              "   'patterns': [\"why do i crave depression ? it ' s not entirely true to say i enjoy being sad , but i always find a way to feel that way . i listen to sad music , read tragic stories , and , in a twisted way , like how bad it makes me feel . i focus on negative aspects of my life even if they aren ' t legitimate or i just make it seem negative .\"],\n",
              "   'responses': ['if you find yourself arguing with your mom , stop',\n",
              "    'it may also be helpful to make a list of your concerns or fears about being away from your family',\n",
              "    'i believe that for results that last , the best approach is to understand why someone feels like doing a certain behavior',\n",
              "    'a good spouse sacrifices their needs to see the other person happy',\n",
              "    'i would encourage you to look for a trauma therapist who offers a sliding scale or pro bono services',\n",
              "    '\" \" you don \\' t',\n",
              "    \"since you don ' t know what to do , then for right now postpone your wedding date\",\n",
              "    'let me first say that i am sorry you are going through this',\n",
              "    \"it sounds like you are noticing that you are drawn towards sad and negative content and it ' s hard to understand why . this may sound counter - intuitive , but sometimes we do things that on the surface may look problematic ( or even cause us some real problems ) because it serves us in some unseen way . a simple example would be somebody who is addicted to a substance ; their addiction may be causing serious problems in their life , and they may even know it , but the addiction serves them by helping them to avoid painful feelings that they anticipate having if they quit using . now i am not saying that what you describe is an addiction , it is just a really illustrative example of the unseen benefit . one thing i would be wondering about is what is the unseen benefit of seeking out sad and negative content ? i ' d also be wondering what your relationship is to other feelings . these are things you may benefit from exploring with a competent therapist .\"],\n",
              "   'tag': 'why'},\n",
              "  {'context_set': '',\n",
              "   'patterns': [\"i ' m seriously unhappy with everything in my life but i know i don ' t have any reason to feel this way i can ' t even smile or fake one . i can ' t feel happiness about anything and i can ' t show love towards another person not even my girlfriend . i hate myself sometimes . all i see is ugly . i can ' t get over the loss of a loved one and i ' m not close to my family . what can i do ?\"],\n",
              "   'responses': [\"the problem is how long you ' re holding it in your hand\",\n",
              "    'i wish you the best',\n",
              "    'what would the worst part be',\n",
              "    'part of the therapy process is to look at your feelings , and to feel what you are actually feeling ( instead of what you think you should feel )',\n",
              "    'we call these \" comorbid \" conditions , which means that two or more mental health problems exist at one time',\n",
              "    'you deserve the help just as much as anyone else',\n",
              "    'in fact , all of what you described points to the importance of you seeking help in order to cope with the many challenges in your life',\n",
              "    'heck , sure thing , hun',\n",
              "    \"trust and believe your own feelings . emotions are real and reflect how someone feels about a situation . since you ' re sad about losing a loved one , be patient w your feelings about this . basically , be guided by how you feel and eventually you will feel different emotions which i hope will be happier ones .\"],\n",
              "   'tag': 'heal'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['is there anything i can do about my depression and anxiety ? i have been dealing with depression and anxiety for a number of years . i have been on medication , but lately my depression has felt worse . can counseling help ?'],\n",
              "   'responses': ['being a parent can be all - consuming',\n",
              "    'if you have difficulty initiating self - care routine talk to your therapist about what motivates you and pushes you to do things , you might find the key during the process',\n",
              "    'hi anaheim , relationships with therapists have some things in common with other relationships ; they work best if there is dialogue about what your hopes , thoughts , emotions and needs are',\n",
              "    'hi bethlehem , you have a big decision to make',\n",
              "    'breath in and out of that space',\n",
              "    'you could also contact your physician or a psychiatrist to discuss medication options if it ’ s too challenging to begin basic self - care',\n",
              "    'if not that , ive sometimes encouraged folk to just leave some information on depression and how family can help like a pamphlet or handout on a table or around the house',\n",
              "    'when to seek professional help',\n",
              "    'thank you for asking this important question . i find that there are three steps to getting ready for treatment . step one is expressing interest in wanting to receiving treatment for the outcome of positive behavioral change . congratulations you did the first step ! you are showing your readiness to start counseling by asking this question . now the second step is to find a counselor who specializes in treating clients with anxiety and depression . the therapeutic orientations i have found to be helpful in treating clients with anxiety and depression are a combination of cognitive behavioral therapy with mindfulness , and solution focused brief therapy . receiving meditation for your symptoms if part of the treatment , and the other part is receiving counseling to increase your resilience for future events . research has found that medication and psychotherapy treatments together shows the most effective outcome for depression . the third step is to increase your positive self - talk to motivate yourself to attend treatment . as counselors , we are aware of the anxieties and fears that are associated with talking to a new professional for the first time . however , remind yourself that you are doing this to improve your well being . i hope this was helpful , and good luck with your treatment journey .'],\n",
              "   'tag': 'Solution'}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzaWrmMopT6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = []\n",
        "labels =[]\n",
        "docs_x = []\n",
        "docs_y = []"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbZ1qKdTV6Ut",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "eb62633c-b2e4-4f4b-af32-0f147e97db30"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwYeIAmIpely",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for intent in data[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "      #stemming\n",
        "        wrds = nltk.word_tokenize(pattern)\n",
        "        #addind the words in list\n",
        "        words.extend(wrds)\n",
        "        docs_x.append(wrds)\n",
        "        docs_y.append(intent[\"tag\"])\n",
        "\n",
        "    if intent[\"tag\"] not in labels:\n",
        "        labels.append(intent[\"tag\"])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Gg56k-degXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\n",
        "#set remove all the duplicate elements\n",
        "words = sorted(list(set(words)))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pne6JKVpyJfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = sorted(labels)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX6GJxrCxl_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training = []\n",
        "output = []\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfAnoeDS1Hd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_empty = [0 for _ in range(len(labels))]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liqZz27Y2JjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for x, doc in enumerate(docs_x):\n",
        "    bag = []\n",
        "\n",
        "    wrds = [stemmer.stem(w.lower()) for w in doc]\n",
        "\n",
        "    for w in words:\n",
        "        if w in wrds:\n",
        "            bag.append(1)\n",
        "        else:\n",
        "            bag.append(0)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWd-nGyh2N8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    output_row = out_empty[:]\n",
        "    output_row[labels.index(docs_y[x])] = 1\n",
        "\n",
        "    training.append(bag)\n",
        "    output.append(output_row)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrPvMlqZ23vE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "training = numpy.array(training)\n",
        "output = numpy.array(output)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWyHKd1J42kW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reseting all the previous settings\n",
        "tensorflow.reset_default_graph()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwCBcr1d4-7K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f2ab260a-f411-41c2-ef58-cff0c13be6c3"
      },
      "source": [
        "\n",
        "net = tflearn.input_data(shape=[None, len(training[0])])\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/layers/core.py:81: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7FMALDL6VgP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "76d9eb44-4c4e-4aed-b33f-dfd11c222330"
      },
      "source": [
        "net = tflearn.fully_connected(net, 8)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/layers/core.py:145: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/initializations.py:174: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh2Y7CE96Z4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = tflearn.fully_connected(net, 8)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TonpnxMP6c1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-_4Biov6gns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "de4d2c4f-4526-4c05-c125-b67073cced1d"
      },
      "source": [
        "net = tflearn.regression(net)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/optimizers.py:238: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/objectives.py:70: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/layers/estimator.py:189: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:571: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqo4d6migBMi",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO7IfHEL6kyR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "bf3082e5-90e2-4513-bca2-57f0ee97ac86"
      },
      "source": [
        "\n",
        "model = tflearn.DNN(net)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:115: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/summaries.py:46: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:164: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:165: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:166: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:167: The name tf.get_collection_ref is deprecated. Please use tf.compat.v1.get_collection_ref instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0kMXzX1-SRC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4a35261-e21a-416a-fee5-f292b1fb4cff"
      },
      "source": [
        "model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
        "model.save(\"model.tflearn\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Run id: U57Z91\n",
            "Log directory: /tmp/tflearn_logs/\n",
            "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
            "---------------------------------\n",
            "Training samples: 1\n",
            "Validation samples: 0\n",
            "--\n",
            "Training Step: 1  | time: 0.141s\n",
            "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 2  | total loss: \u001b[1m\u001b[32m2.43726\u001b[0m\u001b[0m | time: 0.007s\n",
            "| Adam | epoch: 002 | loss: 2.43726 - acc: 0.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 3  | total loss: \u001b[1m\u001b[32m2.65718\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 003 | loss: 2.65718 - acc: 0.8182 -- iter: 1/1\n",
            "--\n",
            "Training Step: 4  | total loss: \u001b[1m\u001b[32m2.69231\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 004 | loss: 2.69231 - acc: 0.9545 -- iter: 1/1\n",
            "--\n",
            "Training Step: 5  | total loss: \u001b[1m\u001b[32m2.69900\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 005 | loss: 2.69900 - acc: 0.9860 -- iter: 1/1\n",
            "--\n",
            "Training Step: 6  | total loss: \u001b[1m\u001b[32m2.69956\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 006 | loss: 2.69956 - acc: 0.9950 -- iter: 1/1\n",
            "--\n",
            "Training Step: 7  | total loss: \u001b[1m\u001b[32m2.69847\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 007 | loss: 2.69847 - acc: 0.9980 -- iter: 1/1\n",
            "--\n",
            "Training Step: 8  | total loss: \u001b[1m\u001b[32m2.69683\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 008 | loss: 2.69683 - acc: 0.9991 -- iter: 1/1\n",
            "--\n",
            "Training Step: 9  | total loss: \u001b[1m\u001b[32m2.69498\u001b[0m\u001b[0m | time: 0.007s\n",
            "| Adam | epoch: 009 | loss: 2.69498 - acc: 0.9996 -- iter: 1/1\n",
            "--\n",
            "Training Step: 10  | total loss: \u001b[1m\u001b[32m2.69301\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 010 | loss: 2.69301 - acc: 0.9998 -- iter: 1/1\n",
            "--\n",
            "Training Step: 11  | total loss: \u001b[1m\u001b[32m2.69097\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 011 | loss: 2.69097 - acc: 0.9999 -- iter: 1/1\n",
            "--\n",
            "Training Step: 12  | total loss: \u001b[1m\u001b[32m2.68885\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 012 | loss: 2.68885 - acc: 0.9999 -- iter: 1/1\n",
            "--\n",
            "Training Step: 13  | total loss: \u001b[1m\u001b[32m2.68667\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 013 | loss: 2.68667 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 14  | total loss: \u001b[1m\u001b[32m2.68441\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 014 | loss: 2.68441 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 15  | total loss: \u001b[1m\u001b[32m2.68207\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 015 | loss: 2.68207 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 16  | total loss: \u001b[1m\u001b[32m2.67964\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 016 | loss: 2.67964 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 17  | total loss: \u001b[1m\u001b[32m2.67711\u001b[0m\u001b[0m | time: 0.008s\n",
            "| Adam | epoch: 017 | loss: 2.67711 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 18  | total loss: \u001b[1m\u001b[32m2.67447\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 018 | loss: 2.67447 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 19  | total loss: \u001b[1m\u001b[32m2.67170\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 019 | loss: 2.67170 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 20  | total loss: \u001b[1m\u001b[32m2.66879\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 020 | loss: 2.66879 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 21  | total loss: \u001b[1m\u001b[32m2.66572\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 021 | loss: 2.66572 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 22  | total loss: \u001b[1m\u001b[32m2.66248\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 022 | loss: 2.66248 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 23  | total loss: \u001b[1m\u001b[32m2.65903\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 023 | loss: 2.65903 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 24  | total loss: \u001b[1m\u001b[32m2.65537\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 024 | loss: 2.65537 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 25  | total loss: \u001b[1m\u001b[32m2.65145\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 025 | loss: 2.65145 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 26  | total loss: \u001b[1m\u001b[32m2.64726\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 026 | loss: 2.64726 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 27  | total loss: \u001b[1m\u001b[32m2.64277\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 027 | loss: 2.64277 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 28  | total loss: \u001b[1m\u001b[32m2.63793\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 028 | loss: 2.63793 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 29  | total loss: \u001b[1m\u001b[32m2.63272\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 029 | loss: 2.63272 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 30  | total loss: \u001b[1m\u001b[32m2.62710\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 030 | loss: 2.62710 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 31  | total loss: \u001b[1m\u001b[32m2.62102\u001b[0m\u001b[0m | time: 0.008s\n",
            "| Adam | epoch: 031 | loss: 2.62102 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 32  | total loss: \u001b[1m\u001b[32m2.61443\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 032 | loss: 2.61443 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 33  | total loss: \u001b[1m\u001b[32m2.59955\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 033 | loss: 2.59955 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 34  | total loss: \u001b[1m\u001b[32m2.59955\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 034 | loss: 2.59955 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 35  | total loss: \u001b[1m\u001b[32m2.59114\u001b[0m\u001b[0m | time: 0.008s\n",
            "| Adam | epoch: 035 | loss: 2.59114 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 36  | total loss: \u001b[1m\u001b[32m2.58200\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 036 | loss: 2.58200 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 37  | total loss: \u001b[1m\u001b[32m2.57207\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 037 | loss: 2.57207 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 38  | total loss: \u001b[1m\u001b[32m2.56129\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 038 | loss: 2.56129 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 39  | total loss: \u001b[1m\u001b[32m2.54956\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 039 | loss: 2.54956 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 40  | total loss: \u001b[1m\u001b[32m2.53682\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 040 | loss: 2.53682 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 41  | total loss: \u001b[1m\u001b[32m2.52298\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 041 | loss: 2.52298 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 42  | total loss: \u001b[1m\u001b[32m2.50795\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 042 | loss: 2.50795 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 43  | total loss: \u001b[1m\u001b[32m2.49164\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 043 | loss: 2.49164 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 44  | total loss: \u001b[1m\u001b[32m2.47395\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 044 | loss: 2.47395 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 45  | total loss: \u001b[1m\u001b[32m2.45478\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 045 | loss: 2.45478 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 46  | total loss: \u001b[1m\u001b[32m2.43402\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 046 | loss: 2.43402 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 47  | total loss: \u001b[1m\u001b[32m2.41156\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 047 | loss: 2.41156 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 48  | total loss: \u001b[1m\u001b[32m2.38729\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 048 | loss: 2.38729 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 49  | total loss: \u001b[1m\u001b[32m2.36108\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 049 | loss: 2.36108 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 50  | total loss: \u001b[1m\u001b[32m2.33281\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 050 | loss: 2.33281 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 51  | total loss: \u001b[1m\u001b[32m2.30237\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 051 | loss: 2.30237 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 52  | total loss: \u001b[1m\u001b[32m2.26963\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 052 | loss: 2.26963 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 53  | total loss: \u001b[1m\u001b[32m2.23446\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 053 | loss: 2.23446 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 54  | total loss: \u001b[1m\u001b[32m2.19675\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 054 | loss: 2.19675 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 55  | total loss: \u001b[1m\u001b[32m2.15637\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 055 | loss: 2.15637 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 56  | total loss: \u001b[1m\u001b[32m2.11322\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 056 | loss: 2.11322 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 57  | total loss: \u001b[1m\u001b[32m2.06719\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 057 | loss: 2.06719 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 58  | total loss: \u001b[1m\u001b[32m2.01820\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 058 | loss: 2.01820 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 59  | total loss: \u001b[1m\u001b[32m1.96617\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 059 | loss: 1.96617 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 60  | total loss: \u001b[1m\u001b[32m1.91106\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 060 | loss: 1.91106 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 61  | total loss: \u001b[1m\u001b[32m1.85286\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 061 | loss: 1.85286 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 62  | total loss: \u001b[1m\u001b[32m1.79158\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 062 | loss: 1.79158 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 63  | total loss: \u001b[1m\u001b[32m1.72729\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 063 | loss: 1.72729 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 64  | total loss: \u001b[1m\u001b[32m1.66011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 064 | loss: 1.66011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 65  | total loss: \u001b[1m\u001b[32m1.59023\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 065 | loss: 1.59023 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 66  | total loss: \u001b[1m\u001b[32m1.51791\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 066 | loss: 1.51791 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 67  | total loss: \u001b[1m\u001b[32m1.44349\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 067 | loss: 1.44349 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 68  | total loss: \u001b[1m\u001b[32m1.36740\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 068 | loss: 1.36740 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 69  | total loss: \u001b[1m\u001b[32m1.29017\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 069 | loss: 1.29017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 70  | total loss: \u001b[1m\u001b[32m1.21238\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 070 | loss: 1.21238 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 71  | total loss: \u001b[1m\u001b[32m1.13470\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 071 | loss: 1.13470 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 72  | total loss: \u001b[1m\u001b[32m1.05782\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 072 | loss: 1.05782 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 73  | total loss: \u001b[1m\u001b[32m0.98245\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 073 | loss: 0.98245 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 74  | total loss: \u001b[1m\u001b[32m0.90926\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 074 | loss: 0.90926 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 75  | total loss: \u001b[1m\u001b[32m0.83886\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 075 | loss: 0.83886 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 76  | total loss: \u001b[1m\u001b[32m0.77175\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 076 | loss: 0.77175 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 77  | total loss: \u001b[1m\u001b[32m0.70831\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 077 | loss: 0.70831 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 78  | total loss: \u001b[1m\u001b[32m0.64880\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 078 | loss: 0.64880 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 79  | total loss: \u001b[1m\u001b[32m0.59336\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 079 | loss: 0.59336 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 80  | total loss: \u001b[1m\u001b[32m0.54200\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 080 | loss: 0.54200 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 81  | total loss: \u001b[1m\u001b[32m0.49467\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 081 | loss: 0.49467 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 82  | total loss: \u001b[1m\u001b[32m0.45121\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 082 | loss: 0.45121 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 83  | total loss: \u001b[1m\u001b[32m0.41101\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 083 | loss: 0.41101 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 84  | total loss: \u001b[1m\u001b[32m0.37396\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 084 | loss: 0.37396 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 85  | total loss: \u001b[1m\u001b[32m0.33992\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 085 | loss: 0.33992 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 86  | total loss: \u001b[1m\u001b[32m0.30874\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 086 | loss: 0.30874 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 87  | total loss: \u001b[1m\u001b[32m0.28023\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 087 | loss: 0.28023 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 88  | total loss: \u001b[1m\u001b[32m0.25423\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 088 | loss: 0.25423 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 89  | total loss: \u001b[1m\u001b[32m0.23053\u001b[0m\u001b[0m | time: 0.007s\n",
            "| Adam | epoch: 089 | loss: 0.23053 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 90  | total loss: \u001b[1m\u001b[32m0.20898\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 090 | loss: 0.20898 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 91  | total loss: \u001b[1m\u001b[32m0.18939\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 091 | loss: 0.18939 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 92  | total loss: \u001b[1m\u001b[32m0.17160\u001b[0m\u001b[0m | time: 0.007s\n",
            "| Adam | epoch: 092 | loss: 0.17160 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 93  | total loss: \u001b[1m\u001b[32m0.15547\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 093 | loss: 0.15547 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 94  | total loss: \u001b[1m\u001b[32m0.14084\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 094 | loss: 0.14084 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 95  | total loss: \u001b[1m\u001b[32m0.12758\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 095 | loss: 0.12758 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 96  | total loss: \u001b[1m\u001b[32m0.11557\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 096 | loss: 0.11557 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 97  | total loss: \u001b[1m\u001b[32m0.10470\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 097 | loss: 0.10470 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 98  | total loss: \u001b[1m\u001b[32m0.09486\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 098 | loss: 0.09486 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 99  | total loss: \u001b[1m\u001b[32m0.08595\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 099 | loss: 0.08595 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 100  | total loss: \u001b[1m\u001b[32m0.07790\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 100 | loss: 0.07790 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 101  | total loss: \u001b[1m\u001b[32m0.07061\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 101 | loss: 0.07061 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 102  | total loss: \u001b[1m\u001b[32m0.06403\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 102 | loss: 0.06403 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 103  | total loss: \u001b[1m\u001b[32m0.05807\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 103 | loss: 0.05807 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 104  | total loss: \u001b[1m\u001b[32m0.05269\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 104 | loss: 0.05269 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 105  | total loss: \u001b[1m\u001b[32m0.04782\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 105 | loss: 0.04782 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 106  | total loss: \u001b[1m\u001b[32m0.04343\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 106 | loss: 0.04343 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 107  | total loss: \u001b[1m\u001b[32m0.03945\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 107 | loss: 0.03945 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 108  | total loss: \u001b[1m\u001b[32m0.03586\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 108 | loss: 0.03586 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 109  | total loss: \u001b[1m\u001b[32m0.03262\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 109 | loss: 0.03262 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 110  | total loss: \u001b[1m\u001b[32m0.02968\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 110 | loss: 0.02968 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 111  | total loss: \u001b[1m\u001b[32m0.02703\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 111 | loss: 0.02703 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 112  | total loss: \u001b[1m\u001b[32m0.02464\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 112 | loss: 0.02464 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 113  | total loss: \u001b[1m\u001b[32m0.02247\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 113 | loss: 0.02247 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 114  | total loss: \u001b[1m\u001b[32m0.02052\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 114 | loss: 0.02052 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 115  | total loss: \u001b[1m\u001b[32m0.01875\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 115 | loss: 0.01875 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 116  | total loss: \u001b[1m\u001b[32m0.01715\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 116 | loss: 0.01715 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 117  | total loss: \u001b[1m\u001b[32m0.01571\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 117 | loss: 0.01571 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 118  | total loss: \u001b[1m\u001b[32m0.01440\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 118 | loss: 0.01440 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 119  | total loss: \u001b[1m\u001b[32m0.01322\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 119 | loss: 0.01322 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 120  | total loss: \u001b[1m\u001b[32m0.01216\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 120 | loss: 0.01216 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 121  | total loss: \u001b[1m\u001b[32m0.01119\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 121 | loss: 0.01119 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 122  | total loss: \u001b[1m\u001b[32m0.01032\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 122 | loss: 0.01032 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 123  | total loss: \u001b[1m\u001b[32m0.00953\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 123 | loss: 0.00953 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 124  | total loss: \u001b[1m\u001b[32m0.00882\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 124 | loss: 0.00882 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 125  | total loss: \u001b[1m\u001b[32m0.00817\u001b[0m\u001b[0m | time: 0.009s\n",
            "| Adam | epoch: 125 | loss: 0.00817 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 126  | total loss: \u001b[1m\u001b[32m0.00758\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 126 | loss: 0.00758 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 127  | total loss: \u001b[1m\u001b[32m0.00705\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 127 | loss: 0.00705 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 128  | total loss: \u001b[1m\u001b[32m0.00658\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 128 | loss: 0.00658 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 129  | total loss: \u001b[1m\u001b[32m0.00614\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 129 | loss: 0.00614 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 130  | total loss: \u001b[1m\u001b[32m0.00575\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 130 | loss: 0.00575 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 131  | total loss: \u001b[1m\u001b[32m0.00539\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 131 | loss: 0.00539 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 132  | total loss: \u001b[1m\u001b[32m0.00507\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 132 | loss: 0.00507 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 133  | total loss: \u001b[1m\u001b[32m0.00477\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 133 | loss: 0.00477 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 134  | total loss: \u001b[1m\u001b[32m0.00451\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 134 | loss: 0.00451 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 135  | total loss: \u001b[1m\u001b[32m0.00426\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 135 | loss: 0.00426 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 136  | total loss: \u001b[1m\u001b[32m0.00404\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 136 | loss: 0.00404 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 137  | total loss: \u001b[1m\u001b[32m0.00384\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 137 | loss: 0.00384 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 138  | total loss: \u001b[1m\u001b[32m0.00366\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 138 | loss: 0.00366 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 139  | total loss: \u001b[1m\u001b[32m0.00350\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 139 | loss: 0.00350 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 140  | total loss: \u001b[1m\u001b[32m0.00335\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 140 | loss: 0.00335 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 141  | total loss: \u001b[1m\u001b[32m0.00321\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 141 | loss: 0.00321 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 142  | total loss: \u001b[1m\u001b[32m0.00308\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 142 | loss: 0.00308 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 143  | total loss: \u001b[1m\u001b[32m0.00297\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 143 | loss: 0.00297 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 144  | total loss: \u001b[1m\u001b[32m0.00286\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 144 | loss: 0.00286 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 145  | total loss: \u001b[1m\u001b[32m0.00277\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 145 | loss: 0.00277 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 146  | total loss: \u001b[1m\u001b[32m0.00268\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 146 | loss: 0.00268 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 147  | total loss: \u001b[1m\u001b[32m0.00260\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 147 | loss: 0.00260 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 148  | total loss: \u001b[1m\u001b[32m0.00252\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 148 | loss: 0.00252 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 149  | total loss: \u001b[1m\u001b[32m0.00245\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 149 | loss: 0.00245 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 150  | total loss: \u001b[1m\u001b[32m0.00239\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 150 | loss: 0.00239 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 151  | total loss: \u001b[1m\u001b[32m0.00233\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 151 | loss: 0.00233 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 152  | total loss: \u001b[1m\u001b[32m0.00228\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 152 | loss: 0.00228 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 153  | total loss: \u001b[1m\u001b[32m0.00223\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 153 | loss: 0.00223 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 154  | total loss: \u001b[1m\u001b[32m0.00218\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 154 | loss: 0.00218 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 155  | total loss: \u001b[1m\u001b[32m0.00214\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 155 | loss: 0.00214 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 156  | total loss: \u001b[1m\u001b[32m0.00210\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 156 | loss: 0.00210 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 157  | total loss: \u001b[1m\u001b[32m0.00206\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 157 | loss: 0.00206 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 158  | total loss: \u001b[1m\u001b[32m0.00203\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 158 | loss: 0.00203 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 159  | total loss: \u001b[1m\u001b[32m0.00200\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 159 | loss: 0.00200 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 160  | total loss: \u001b[1m\u001b[32m0.00197\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 160 | loss: 0.00197 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 161  | total loss: \u001b[1m\u001b[32m0.00194\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 161 | loss: 0.00194 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 162  | total loss: \u001b[1m\u001b[32m0.00191\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 162 | loss: 0.00191 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 163  | total loss: \u001b[1m\u001b[32m0.00188\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 163 | loss: 0.00188 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 164  | total loss: \u001b[1m\u001b[32m0.00186\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 164 | loss: 0.00186 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 165  | total loss: \u001b[1m\u001b[32m0.00184\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 165 | loss: 0.00184 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 166  | total loss: \u001b[1m\u001b[32m0.00182\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 166 | loss: 0.00182 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 167  | total loss: \u001b[1m\u001b[32m0.00179\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 167 | loss: 0.00179 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 168  | total loss: \u001b[1m\u001b[32m0.00177\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 168 | loss: 0.00177 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 169  | total loss: \u001b[1m\u001b[32m0.00176\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 169 | loss: 0.00176 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 170  | total loss: \u001b[1m\u001b[32m0.00174\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 170 | loss: 0.00174 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 171  | total loss: \u001b[1m\u001b[32m0.00172\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 171 | loss: 0.00172 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 172  | total loss: \u001b[1m\u001b[32m0.00170\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 172 | loss: 0.00170 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 173  | total loss: \u001b[1m\u001b[32m0.00169\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 173 | loss: 0.00169 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 174  | total loss: \u001b[1m\u001b[32m0.00167\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 174 | loss: 0.00167 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 175  | total loss: \u001b[1m\u001b[32m0.00166\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 175 | loss: 0.00166 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 176  | total loss: \u001b[1m\u001b[32m0.00164\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 176 | loss: 0.00164 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 177  | total loss: \u001b[1m\u001b[32m0.00163\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 177 | loss: 0.00163 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 178  | total loss: \u001b[1m\u001b[32m0.00161\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 178 | loss: 0.00161 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 179  | total loss: \u001b[1m\u001b[32m0.00160\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 179 | loss: 0.00160 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 180  | total loss: \u001b[1m\u001b[32m0.00159\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 180 | loss: 0.00159 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 181  | total loss: \u001b[1m\u001b[32m0.00157\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 181 | loss: 0.00157 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 182  | total loss: \u001b[1m\u001b[32m0.00156\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 182 | loss: 0.00156 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 183  | total loss: \u001b[1m\u001b[32m0.00155\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 183 | loss: 0.00155 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 184  | total loss: \u001b[1m\u001b[32m0.00154\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 184 | loss: 0.00154 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 185  | total loss: \u001b[1m\u001b[32m0.00152\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 185 | loss: 0.00152 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 186  | total loss: \u001b[1m\u001b[32m0.00151\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 186 | loss: 0.00151 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 187  | total loss: \u001b[1m\u001b[32m0.00150\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 187 | loss: 0.00150 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 188  | total loss: \u001b[1m\u001b[32m0.00149\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 188 | loss: 0.00149 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 189  | total loss: \u001b[1m\u001b[32m0.00148\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 189 | loss: 0.00148 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 190  | total loss: \u001b[1m\u001b[32m0.00147\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 190 | loss: 0.00147 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 191  | total loss: \u001b[1m\u001b[32m0.00146\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 191 | loss: 0.00146 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 192  | total loss: \u001b[1m\u001b[32m0.00145\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 192 | loss: 0.00145 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 193  | total loss: \u001b[1m\u001b[32m0.00144\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 193 | loss: 0.00144 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 194  | total loss: \u001b[1m\u001b[32m0.00143\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 194 | loss: 0.00143 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 195  | total loss: \u001b[1m\u001b[32m0.00142\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 195 | loss: 0.00142 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 196  | total loss: \u001b[1m\u001b[32m0.00141\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 196 | loss: 0.00141 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 197  | total loss: \u001b[1m\u001b[32m0.00140\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 197 | loss: 0.00140 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 198  | total loss: \u001b[1m\u001b[32m0.00139\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 198 | loss: 0.00139 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 199  | total loss: \u001b[1m\u001b[32m0.00138\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 199 | loss: 0.00138 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 200  | total loss: \u001b[1m\u001b[32m0.00137\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 200 | loss: 0.00137 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 201  | total loss: \u001b[1m\u001b[32m0.00136\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 201 | loss: 0.00136 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 202  | total loss: \u001b[1m\u001b[32m0.00135\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 202 | loss: 0.00135 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 203  | total loss: \u001b[1m\u001b[32m0.00134\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 203 | loss: 0.00134 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 204  | total loss: \u001b[1m\u001b[32m0.00133\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 204 | loss: 0.00133 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 205  | total loss: \u001b[1m\u001b[32m0.00133\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 205 | loss: 0.00133 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 206  | total loss: \u001b[1m\u001b[32m0.00132\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 206 | loss: 0.00132 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 207  | total loss: \u001b[1m\u001b[32m0.00131\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 207 | loss: 0.00131 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 208  | total loss: \u001b[1m\u001b[32m0.00130\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 208 | loss: 0.00130 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 209  | total loss: \u001b[1m\u001b[32m0.00129\u001b[0m\u001b[0m | time: 0.002s\n",
            "| Adam | epoch: 209 | loss: 0.00129 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 210  | total loss: \u001b[1m\u001b[32m0.00128\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 210 | loss: 0.00128 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 211  | total loss: \u001b[1m\u001b[32m0.00127\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 211 | loss: 0.00127 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 212  | total loss: \u001b[1m\u001b[32m0.00127\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 212 | loss: 0.00127 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 213  | total loss: \u001b[1m\u001b[32m0.00126\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 213 | loss: 0.00126 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 214  | total loss: \u001b[1m\u001b[32m0.00125\u001b[0m\u001b[0m | time: 0.007s\n",
            "| Adam | epoch: 214 | loss: 0.00125 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 215  | total loss: \u001b[1m\u001b[32m0.00124\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 215 | loss: 0.00124 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 216  | total loss: \u001b[1m\u001b[32m0.00123\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 216 | loss: 0.00123 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 217  | total loss: \u001b[1m\u001b[32m0.00123\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 217 | loss: 0.00123 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 218  | total loss: \u001b[1m\u001b[32m0.00122\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 218 | loss: 0.00122 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 219  | total loss: \u001b[1m\u001b[32m0.00121\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 219 | loss: 0.00121 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 220  | total loss: \u001b[1m\u001b[32m0.00120\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 220 | loss: 0.00120 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 221  | total loss: \u001b[1m\u001b[32m0.00120\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 221 | loss: 0.00120 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 222  | total loss: \u001b[1m\u001b[32m0.00119\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 222 | loss: 0.00119 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 223  | total loss: \u001b[1m\u001b[32m0.00118\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 223 | loss: 0.00118 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 224  | total loss: \u001b[1m\u001b[32m0.00117\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 224 | loss: 0.00117 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 225  | total loss: \u001b[1m\u001b[32m0.00117\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 225 | loss: 0.00117 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 226  | total loss: \u001b[1m\u001b[32m0.00116\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 226 | loss: 0.00116 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 227  | total loss: \u001b[1m\u001b[32m0.00115\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 227 | loss: 0.00115 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 228  | total loss: \u001b[1m\u001b[32m0.00115\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 228 | loss: 0.00115 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 229  | total loss: \u001b[1m\u001b[32m0.00114\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 229 | loss: 0.00114 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 230  | total loss: \u001b[1m\u001b[32m0.00113\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 230 | loss: 0.00113 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 231  | total loss: \u001b[1m\u001b[32m0.00113\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 231 | loss: 0.00113 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 232  | total loss: \u001b[1m\u001b[32m0.00112\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 232 | loss: 0.00112 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 233  | total loss: \u001b[1m\u001b[32m0.00111\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 233 | loss: 0.00111 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 234  | total loss: \u001b[1m\u001b[32m0.00110\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 234 | loss: 0.00110 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 235  | total loss: \u001b[1m\u001b[32m0.00110\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 235 | loss: 0.00110 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 236  | total loss: \u001b[1m\u001b[32m0.00109\u001b[0m\u001b[0m | time: 0.008s\n",
            "| Adam | epoch: 236 | loss: 0.00109 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 237  | total loss: \u001b[1m\u001b[32m0.00109\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 237 | loss: 0.00109 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 238  | total loss: \u001b[1m\u001b[32m0.00108\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 238 | loss: 0.00108 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.00107\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 239 | loss: 0.00107 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.00107\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 240 | loss: 0.00107 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 241  | total loss: \u001b[1m\u001b[32m0.00106\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 241 | loss: 0.00106 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 242  | total loss: \u001b[1m\u001b[32m0.00105\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 242 | loss: 0.00105 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 243  | total loss: \u001b[1m\u001b[32m0.00105\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 243 | loss: 0.00105 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 244  | total loss: \u001b[1m\u001b[32m0.00104\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 244 | loss: 0.00104 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 245  | total loss: \u001b[1m\u001b[32m0.00104\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 245 | loss: 0.00104 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 246  | total loss: \u001b[1m\u001b[32m0.00103\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 246 | loss: 0.00103 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 247  | total loss: \u001b[1m\u001b[32m0.00102\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 247 | loss: 0.00102 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 248  | total loss: \u001b[1m\u001b[32m0.00102\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 248 | loss: 0.00102 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 249  | total loss: \u001b[1m\u001b[32m0.00101\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 249 | loss: 0.00101 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 250  | total loss: \u001b[1m\u001b[32m0.00101\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 250 | loss: 0.00101 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 251  | total loss: \u001b[1m\u001b[32m0.00100\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 251 | loss: 0.00100 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 252  | total loss: \u001b[1m\u001b[32m0.00099\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 252 | loss: 0.00099 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 253  | total loss: \u001b[1m\u001b[32m0.00099\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 253 | loss: 0.00099 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 254  | total loss: \u001b[1m\u001b[32m0.00098\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 254 | loss: 0.00098 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 255  | total loss: \u001b[1m\u001b[32m0.00098\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 255 | loss: 0.00098 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 256  | total loss: \u001b[1m\u001b[32m0.00097\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 256 | loss: 0.00097 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 257  | total loss: \u001b[1m\u001b[32m0.00097\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 257 | loss: 0.00097 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 258  | total loss: \u001b[1m\u001b[32m0.00096\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 258 | loss: 0.00096 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 259  | total loss: \u001b[1m\u001b[32m0.00096\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 259 | loss: 0.00096 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 260  | total loss: \u001b[1m\u001b[32m0.00095\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 260 | loss: 0.00095 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 261  | total loss: \u001b[1m\u001b[32m0.00094\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 261 | loss: 0.00094 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 262  | total loss: \u001b[1m\u001b[32m0.00094\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 262 | loss: 0.00094 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 263  | total loss: \u001b[1m\u001b[32m0.00093\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 263 | loss: 0.00093 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 264  | total loss: \u001b[1m\u001b[32m0.00093\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 264 | loss: 0.00093 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 265  | total loss: \u001b[1m\u001b[32m0.00092\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 265 | loss: 0.00092 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 266  | total loss: \u001b[1m\u001b[32m0.00092\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 266 | loss: 0.00092 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 267  | total loss: \u001b[1m\u001b[32m0.00091\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 267 | loss: 0.00091 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 268  | total loss: \u001b[1m\u001b[32m0.00091\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 268 | loss: 0.00091 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 269  | total loss: \u001b[1m\u001b[32m0.00090\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 269 | loss: 0.00090 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 270  | total loss: \u001b[1m\u001b[32m0.00090\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 270 | loss: 0.00090 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 271  | total loss: \u001b[1m\u001b[32m0.00089\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 271 | loss: 0.00089 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 272  | total loss: \u001b[1m\u001b[32m0.00089\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 272 | loss: 0.00089 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 273  | total loss: \u001b[1m\u001b[32m0.00088\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 273 | loss: 0.00088 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 274  | total loss: \u001b[1m\u001b[32m0.00088\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 274 | loss: 0.00088 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 275  | total loss: \u001b[1m\u001b[32m0.00088\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 275 | loss: 0.00088 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 276  | total loss: \u001b[1m\u001b[32m0.00087\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 276 | loss: 0.00087 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 277  | total loss: \u001b[1m\u001b[32m0.00087\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 277 | loss: 0.00087 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 278  | total loss: \u001b[1m\u001b[32m0.00086\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 278 | loss: 0.00086 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 279  | total loss: \u001b[1m\u001b[32m0.00086\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 279 | loss: 0.00086 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 280  | total loss: \u001b[1m\u001b[32m0.00085\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 280 | loss: 0.00085 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 281  | total loss: \u001b[1m\u001b[32m0.00085\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 281 | loss: 0.00085 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 282  | total loss: \u001b[1m\u001b[32m0.00084\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 282 | loss: 0.00084 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 283  | total loss: \u001b[1m\u001b[32m0.00084\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 283 | loss: 0.00084 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 284  | total loss: \u001b[1m\u001b[32m0.00083\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 284 | loss: 0.00083 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 285  | total loss: \u001b[1m\u001b[32m0.00083\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 285 | loss: 0.00083 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 286  | total loss: \u001b[1m\u001b[32m0.00083\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 286 | loss: 0.00083 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 287  | total loss: \u001b[1m\u001b[32m0.00082\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 287 | loss: 0.00082 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 288  | total loss: \u001b[1m\u001b[32m0.00082\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 288 | loss: 0.00082 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 289  | total loss: \u001b[1m\u001b[32m0.00081\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 289 | loss: 0.00081 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 290  | total loss: \u001b[1m\u001b[32m0.00081\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 290 | loss: 0.00081 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 291  | total loss: \u001b[1m\u001b[32m0.00080\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 291 | loss: 0.00080 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 292  | total loss: \u001b[1m\u001b[32m0.00080\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 292 | loss: 0.00080 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 293  | total loss: \u001b[1m\u001b[32m0.00080\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 293 | loss: 0.00080 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 294  | total loss: \u001b[1m\u001b[32m0.00079\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 294 | loss: 0.00079 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 295  | total loss: \u001b[1m\u001b[32m0.00079\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 295 | loss: 0.00079 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 296  | total loss: \u001b[1m\u001b[32m0.00078\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 296 | loss: 0.00078 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 297  | total loss: \u001b[1m\u001b[32m0.00078\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 297 | loss: 0.00078 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 298  | total loss: \u001b[1m\u001b[32m0.00078\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 298 | loss: 0.00078 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 299  | total loss: \u001b[1m\u001b[32m0.00077\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 299 | loss: 0.00077 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 300  | total loss: \u001b[1m\u001b[32m0.00077\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 300 | loss: 0.00077 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 301  | total loss: \u001b[1m\u001b[32m0.00076\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 301 | loss: 0.00076 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 302  | total loss: \u001b[1m\u001b[32m0.00076\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 302 | loss: 0.00076 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 303  | total loss: \u001b[1m\u001b[32m0.00076\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 303 | loss: 0.00076 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 304  | total loss: \u001b[1m\u001b[32m0.00075\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 304 | loss: 0.00075 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 305  | total loss: \u001b[1m\u001b[32m0.00075\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 305 | loss: 0.00075 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 306  | total loss: \u001b[1m\u001b[32m0.00074\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 306 | loss: 0.00074 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 307  | total loss: \u001b[1m\u001b[32m0.00074\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 307 | loss: 0.00074 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 308  | total loss: \u001b[1m\u001b[32m0.00074\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 308 | loss: 0.00074 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 309  | total loss: \u001b[1m\u001b[32m0.00073\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 309 | loss: 0.00073 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 310  | total loss: \u001b[1m\u001b[32m0.00073\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 310 | loss: 0.00073 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 311  | total loss: \u001b[1m\u001b[32m0.00073\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 311 | loss: 0.00073 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 312  | total loss: \u001b[1m\u001b[32m0.00072\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 312 | loss: 0.00072 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 313  | total loss: \u001b[1m\u001b[32m0.00072\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 313 | loss: 0.00072 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 314  | total loss: \u001b[1m\u001b[32m0.00072\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 314 | loss: 0.00072 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 315  | total loss: \u001b[1m\u001b[32m0.00071\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 315 | loss: 0.00071 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 316  | total loss: \u001b[1m\u001b[32m0.00071\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 316 | loss: 0.00071 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 317  | total loss: \u001b[1m\u001b[32m0.00071\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 317 | loss: 0.00071 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 318  | total loss: \u001b[1m\u001b[32m0.00070\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 318 | loss: 0.00070 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 319  | total loss: \u001b[1m\u001b[32m0.00070\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 319 | loss: 0.00070 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 320  | total loss: \u001b[1m\u001b[32m0.00070\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 320 | loss: 0.00070 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 321  | total loss: \u001b[1m\u001b[32m0.00069\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 321 | loss: 0.00069 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 322  | total loss: \u001b[1m\u001b[32m0.00069\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 322 | loss: 0.00069 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 323  | total loss: \u001b[1m\u001b[32m0.00069\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 323 | loss: 0.00069 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 324  | total loss: \u001b[1m\u001b[32m0.00068\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 324 | loss: 0.00068 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 325  | total loss: \u001b[1m\u001b[32m0.00068\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 325 | loss: 0.00068 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 326  | total loss: \u001b[1m\u001b[32m0.00068\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 326 | loss: 0.00068 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 327  | total loss: \u001b[1m\u001b[32m0.00067\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 327 | loss: 0.00067 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 328  | total loss: \u001b[1m\u001b[32m0.00067\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 328 | loss: 0.00067 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 329  | total loss: \u001b[1m\u001b[32m0.00067\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 329 | loss: 0.00067 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 330  | total loss: \u001b[1m\u001b[32m0.00066\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 330 | loss: 0.00066 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 331  | total loss: \u001b[1m\u001b[32m0.00066\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 331 | loss: 0.00066 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 332  | total loss: \u001b[1m\u001b[32m0.00066\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 332 | loss: 0.00066 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 333  | total loss: \u001b[1m\u001b[32m0.00065\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 333 | loss: 0.00065 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 334  | total loss: \u001b[1m\u001b[32m0.00065\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 334 | loss: 0.00065 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 335  | total loss: \u001b[1m\u001b[32m0.00065\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 335 | loss: 0.00065 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 336  | total loss: \u001b[1m\u001b[32m0.00064\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 336 | loss: 0.00064 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 337  | total loss: \u001b[1m\u001b[32m0.00064\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 337 | loss: 0.00064 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 338  | total loss: \u001b[1m\u001b[32m0.00064\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 338 | loss: 0.00064 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 339  | total loss: \u001b[1m\u001b[32m0.00064\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 339 | loss: 0.00064 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 340  | total loss: \u001b[1m\u001b[32m0.00063\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 340 | loss: 0.00063 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 341  | total loss: \u001b[1m\u001b[32m0.00063\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 341 | loss: 0.00063 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 342  | total loss: \u001b[1m\u001b[32m0.00063\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 342 | loss: 0.00063 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 343  | total loss: \u001b[1m\u001b[32m0.00062\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 343 | loss: 0.00062 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 344  | total loss: \u001b[1m\u001b[32m0.00062\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 344 | loss: 0.00062 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 345  | total loss: \u001b[1m\u001b[32m0.00062\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 345 | loss: 0.00062 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 346  | total loss: \u001b[1m\u001b[32m0.00062\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 346 | loss: 0.00062 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 347  | total loss: \u001b[1m\u001b[32m0.00061\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 347 | loss: 0.00061 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 348  | total loss: \u001b[1m\u001b[32m0.00061\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 348 | loss: 0.00061 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 349  | total loss: \u001b[1m\u001b[32m0.00061\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 349 | loss: 0.00061 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 350  | total loss: \u001b[1m\u001b[32m0.00060\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 350 | loss: 0.00060 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 351  | total loss: \u001b[1m\u001b[32m0.00060\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 351 | loss: 0.00060 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 352  | total loss: \u001b[1m\u001b[32m0.00060\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 352 | loss: 0.00060 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 353  | total loss: \u001b[1m\u001b[32m0.00060\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 353 | loss: 0.00060 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 354  | total loss: \u001b[1m\u001b[32m0.00059\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 354 | loss: 0.00059 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 355  | total loss: \u001b[1m\u001b[32m0.00059\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 355 | loss: 0.00059 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 356  | total loss: \u001b[1m\u001b[32m0.00059\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 356 | loss: 0.00059 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 357  | total loss: \u001b[1m\u001b[32m0.00059\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 357 | loss: 0.00059 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 358  | total loss: \u001b[1m\u001b[32m0.00058\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 358 | loss: 0.00058 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 359  | total loss: \u001b[1m\u001b[32m0.00058\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 359 | loss: 0.00058 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 360  | total loss: \u001b[1m\u001b[32m0.00058\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 360 | loss: 0.00058 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 361  | total loss: \u001b[1m\u001b[32m0.00058\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 361 | loss: 0.00058 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 362  | total loss: \u001b[1m\u001b[32m0.00057\u001b[0m\u001b[0m | time: 0.007s\n",
            "| Adam | epoch: 362 | loss: 0.00057 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 363  | total loss: \u001b[1m\u001b[32m0.00057\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 363 | loss: 0.00057 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 364  | total loss: \u001b[1m\u001b[32m0.00057\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 364 | loss: 0.00057 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 365  | total loss: \u001b[1m\u001b[32m0.00057\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 365 | loss: 0.00057 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 366  | total loss: \u001b[1m\u001b[32m0.00056\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 366 | loss: 0.00056 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 367  | total loss: \u001b[1m\u001b[32m0.00056\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 367 | loss: 0.00056 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 368  | total loss: \u001b[1m\u001b[32m0.00056\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 368 | loss: 0.00056 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 369  | total loss: \u001b[1m\u001b[32m0.00056\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 369 | loss: 0.00056 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 370  | total loss: \u001b[1m\u001b[32m0.00055\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 370 | loss: 0.00055 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 371  | total loss: \u001b[1m\u001b[32m0.00055\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 371 | loss: 0.00055 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 372  | total loss: \u001b[1m\u001b[32m0.00055\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 372 | loss: 0.00055 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 373  | total loss: \u001b[1m\u001b[32m0.00055\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 373 | loss: 0.00055 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 374  | total loss: \u001b[1m\u001b[32m0.00054\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 374 | loss: 0.00054 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 375  | total loss: \u001b[1m\u001b[32m0.00054\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 375 | loss: 0.00054 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 376  | total loss: \u001b[1m\u001b[32m0.00054\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 376 | loss: 0.00054 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 377  | total loss: \u001b[1m\u001b[32m0.00054\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 377 | loss: 0.00054 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 378  | total loss: \u001b[1m\u001b[32m0.00053\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 378 | loss: 0.00053 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 379  | total loss: \u001b[1m\u001b[32m0.00053\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 379 | loss: 0.00053 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 380  | total loss: \u001b[1m\u001b[32m0.00053\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 380 | loss: 0.00053 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 381  | total loss: \u001b[1m\u001b[32m0.00053\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 381 | loss: 0.00053 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 382  | total loss: \u001b[1m\u001b[32m0.00053\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 382 | loss: 0.00053 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 383  | total loss: \u001b[1m\u001b[32m0.00052\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 383 | loss: 0.00052 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 384  | total loss: \u001b[1m\u001b[32m0.00052\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 384 | loss: 0.00052 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 385  | total loss: \u001b[1m\u001b[32m0.00052\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 385 | loss: 0.00052 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 386  | total loss: \u001b[1m\u001b[32m0.00052\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 386 | loss: 0.00052 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 387  | total loss: \u001b[1m\u001b[32m0.00051\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 387 | loss: 0.00051 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 388  | total loss: \u001b[1m\u001b[32m0.00051\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 388 | loss: 0.00051 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 389  | total loss: \u001b[1m\u001b[32m0.00051\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 389 | loss: 0.00051 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 390  | total loss: \u001b[1m\u001b[32m0.00051\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 390 | loss: 0.00051 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 391  | total loss: \u001b[1m\u001b[32m0.00051\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 391 | loss: 0.00051 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 392  | total loss: \u001b[1m\u001b[32m0.00050\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 392 | loss: 0.00050 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 393  | total loss: \u001b[1m\u001b[32m0.00050\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 393 | loss: 0.00050 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 394  | total loss: \u001b[1m\u001b[32m0.00050\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 394 | loss: 0.00050 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 395  | total loss: \u001b[1m\u001b[32m0.00050\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 395 | loss: 0.00050 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 396  | total loss: \u001b[1m\u001b[32m0.00050\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 396 | loss: 0.00050 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 397  | total loss: \u001b[1m\u001b[32m0.00049\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 397 | loss: 0.00049 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 398  | total loss: \u001b[1m\u001b[32m0.00049\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 398 | loss: 0.00049 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 399  | total loss: \u001b[1m\u001b[32m0.00049\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 399 | loss: 0.00049 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.00049\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 400 | loss: 0.00049 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 401  | total loss: \u001b[1m\u001b[32m0.00049\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 401 | loss: 0.00049 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 402  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 402 | loss: 0.00048 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 403  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.007s\n",
            "| Adam | epoch: 403 | loss: 0.00048 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 404  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 404 | loss: 0.00048 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 405  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 405 | loss: 0.00048 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 406  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 406 | loss: 0.00048 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 407  | total loss: \u001b[1m\u001b[32m0.00047\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 407 | loss: 0.00047 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 408  | total loss: \u001b[1m\u001b[32m0.00047\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 408 | loss: 0.00047 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 409  | total loss: \u001b[1m\u001b[32m0.00047\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 409 | loss: 0.00047 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 410  | total loss: \u001b[1m\u001b[32m0.00047\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 410 | loss: 0.00047 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 411  | total loss: \u001b[1m\u001b[32m0.00047\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 411 | loss: 0.00047 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 412  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 412 | loss: 0.00046 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 413  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 413 | loss: 0.00046 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 414  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 414 | loss: 0.00046 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 415  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 415 | loss: 0.00046 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 416  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 416 | loss: 0.00046 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 417  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 417 | loss: 0.00046 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 418  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 418 | loss: 0.00045 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 419  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 419 | loss: 0.00045 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 420  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 420 | loss: 0.00045 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 421  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 421 | loss: 0.00045 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 422  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 422 | loss: 0.00045 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 423  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 423 | loss: 0.00044 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 424  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 424 | loss: 0.00044 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 425  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 425 | loss: 0.00044 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 426  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 426 | loss: 0.00044 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 427  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 427 | loss: 0.00044 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 428  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 428 | loss: 0.00044 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 429  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 429 | loss: 0.00043 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 430  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 430 | loss: 0.00043 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 431  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 431 | loss: 0.00043 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 432  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 432 | loss: 0.00043 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 433  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 433 | loss: 0.00043 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 434  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 434 | loss: 0.00043 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 435  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 435 | loss: 0.00042 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 436  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 436 | loss: 0.00042 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 437  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 437 | loss: 0.00042 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 438  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 438 | loss: 0.00042 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 439  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 439 | loss: 0.00042 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 440  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 440 | loss: 0.00042 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 441  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 441 | loss: 0.00042 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 442  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 442 | loss: 0.00041 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 443  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 443 | loss: 0.00041 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 444  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 444 | loss: 0.00041 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 445  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 445 | loss: 0.00041 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 446  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.002s\n",
            "| Adam | epoch: 446 | loss: 0.00041 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 447  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 447 | loss: 0.00041 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 448  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 448 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 449  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 449 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 450  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 450 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 451  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 451 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 452  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 452 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 453  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 453 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 454  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 454 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 455  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 455 | loss: 0.00039 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 456  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 456 | loss: 0.00039 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 457  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 457 | loss: 0.00039 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 458  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 458 | loss: 0.00039 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 459  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 459 | loss: 0.00039 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 460  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 460 | loss: 0.00039 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 461  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 461 | loss: 0.00039 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 462  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 462 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 463  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 463 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 464  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 464 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 465  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 465 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 466  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 466 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 467  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 467 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 468  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 468 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 469  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 469 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 470  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 470 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 471  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 471 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 472  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 472 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 473  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 473 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 474  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 474 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 475  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 475 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 476  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 476 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 477  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 477 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 478  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 478 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 479  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 479 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 480  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 480 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 481  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 481 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 482  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 482 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 483  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 483 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 484  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 484 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 485  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 485 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 486  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 486 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 487  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 487 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 488  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 488 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 489  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 489 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 490  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 490 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 491  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 491 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 492  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 492 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 493  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 493 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 494  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 494 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 495  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 495 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 496  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 496 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 497  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 497 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 498  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 498 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 499  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 499 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 500  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 500 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 501  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 501 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 502  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 502 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 503  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 503 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 504  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 504 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 505  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 505 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 506  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 506 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 507  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 507 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 508  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 508 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 509  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 509 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 510  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 510 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 511  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 511 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 512  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 512 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 513  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 513 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 514  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 514 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 515  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 515 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 516  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 516 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 517  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 517 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 518  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 518 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 519  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 519 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 520  | total loss: \u001b[1m\u001b[32m0.00031\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 520 | loss: 0.00031 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 521  | total loss: \u001b[1m\u001b[32m0.00031\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 521 | loss: 0.00031 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 522  | total loss: \u001b[1m\u001b[32m0.00031\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 522 | loss: 0.00031 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 523  | total loss: \u001b[1m\u001b[32m0.00031\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 523 | loss: 0.00031 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 524  | total loss: \u001b[1m\u001b[32m0.00031\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 524 | loss: 0.00031 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 525  | total loss: \u001b[1m\u001b[32m0.00031\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 525 | loss: 0.00031 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 526  | total loss: \u001b[1m\u001b[32m0.00031\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 526 | loss: 0.00031 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 527  | total loss: \u001b[1m\u001b[32m0.00031\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 527 | loss: 0.00031 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 528  | total loss: \u001b[1m\u001b[32m0.00031\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 528 | loss: 0.00031 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 529  | total loss: \u001b[1m\u001b[32m0.00031\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 529 | loss: 0.00031 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 530  | total loss: \u001b[1m\u001b[32m0.00030\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 530 | loss: 0.00030 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 531  | total loss: \u001b[1m\u001b[32m0.00030\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 531 | loss: 0.00030 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 532  | total loss: \u001b[1m\u001b[32m0.00030\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 532 | loss: 0.00030 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 533  | total loss: \u001b[1m\u001b[32m0.00030\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 533 | loss: 0.00030 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 534  | total loss: \u001b[1m\u001b[32m0.00030\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 534 | loss: 0.00030 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 535  | total loss: \u001b[1m\u001b[32m0.00030\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 535 | loss: 0.00030 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 536  | total loss: \u001b[1m\u001b[32m0.00030\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 536 | loss: 0.00030 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 537  | total loss: \u001b[1m\u001b[32m0.00030\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 537 | loss: 0.00030 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 538  | total loss: \u001b[1m\u001b[32m0.00030\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 538 | loss: 0.00030 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 539  | total loss: \u001b[1m\u001b[32m0.00030\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 539 | loss: 0.00030 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 540  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 540 | loss: 0.00029 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 541  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 541 | loss: 0.00029 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 542  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 542 | loss: 0.00029 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 543  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 543 | loss: 0.00029 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 544  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 544 | loss: 0.00029 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 545  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 545 | loss: 0.00029 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 546  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 546 | loss: 0.00029 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 547  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 547 | loss: 0.00029 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 548  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 548 | loss: 0.00029 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 549  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 549 | loss: 0.00029 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 550  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 550 | loss: 0.00029 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 551  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 551 | loss: 0.00028 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 552  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 552 | loss: 0.00028 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 553  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 553 | loss: 0.00028 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 554  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 554 | loss: 0.00028 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 555  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 555 | loss: 0.00028 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 556  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 556 | loss: 0.00028 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 557  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 557 | loss: 0.00028 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 558  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.009s\n",
            "| Adam | epoch: 558 | loss: 0.00028 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 559  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 559 | loss: 0.00028 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 560  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.018s\n",
            "| Adam | epoch: 560 | loss: 0.00028 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 561  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.009s\n",
            "| Adam | epoch: 561 | loss: 0.00028 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 562  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 562 | loss: 0.00028 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 563  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 563 | loss: 0.00027 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 564  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 564 | loss: 0.00027 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 565  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 565 | loss: 0.00027 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 566  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 566 | loss: 0.00027 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 567  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 567 | loss: 0.00027 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 568  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 568 | loss: 0.00027 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 569  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 569 | loss: 0.00027 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 570  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 570 | loss: 0.00027 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 571  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 571 | loss: 0.00027 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 572  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 572 | loss: 0.00027 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 573  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 573 | loss: 0.00027 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 574  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 574 | loss: 0.00027 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 575  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 575 | loss: 0.00026 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 576  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 576 | loss: 0.00026 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 577  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 577 | loss: 0.00026 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 578  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 578 | loss: 0.00026 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 579  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 579 | loss: 0.00026 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 580  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 580 | loss: 0.00026 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 581  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 581 | loss: 0.00026 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 582  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 582 | loss: 0.00026 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 583  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 583 | loss: 0.00026 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 584  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 584 | loss: 0.00026 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 585  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 585 | loss: 0.00026 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 586  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 586 | loss: 0.00026 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 587  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 587 | loss: 0.00025 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 588  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 588 | loss: 0.00025 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 589  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 589 | loss: 0.00025 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 590  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 590 | loss: 0.00025 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 591  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 591 | loss: 0.00025 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 592  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 592 | loss: 0.00025 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 593  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 593 | loss: 0.00025 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 594  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 594 | loss: 0.00025 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 595  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 595 | loss: 0.00025 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 596  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 596 | loss: 0.00025 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 597  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 597 | loss: 0.00025 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 598  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 598 | loss: 0.00025 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 599  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 599 | loss: 0.00025 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 600  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 600 | loss: 0.00025 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 601  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 601 | loss: 0.00024 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 602  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 602 | loss: 0.00024 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 603  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 603 | loss: 0.00024 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 604  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 604 | loss: 0.00024 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 605  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 605 | loss: 0.00024 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 606  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 606 | loss: 0.00024 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 607  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 607 | loss: 0.00024 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 608  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 608 | loss: 0.00024 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 609  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 609 | loss: 0.00024 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 610  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 610 | loss: 0.00024 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 611  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 611 | loss: 0.00024 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 612  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 612 | loss: 0.00024 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 613  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 613 | loss: 0.00024 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 614  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 614 | loss: 0.00024 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 615  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 615 | loss: 0.00024 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 616  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 616 | loss: 0.00023 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 617  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 617 | loss: 0.00023 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 618  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 618 | loss: 0.00023 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 619  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 619 | loss: 0.00023 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 620  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 620 | loss: 0.00023 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 621  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 621 | loss: 0.00023 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 622  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 622 | loss: 0.00023 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 623  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 623 | loss: 0.00023 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 624  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 624 | loss: 0.00023 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 625  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 625 | loss: 0.00023 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 626  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 626 | loss: 0.00023 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 627  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 627 | loss: 0.00023 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 628  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 628 | loss: 0.00023 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 629  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 629 | loss: 0.00023 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 630  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 630 | loss: 0.00023 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 631  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 631 | loss: 0.00022 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 632  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 632 | loss: 0.00022 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 633  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 633 | loss: 0.00022 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 634  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 634 | loss: 0.00022 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 635  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 635 | loss: 0.00022 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 636  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 636 | loss: 0.00022 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 637  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 637 | loss: 0.00022 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 638  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 638 | loss: 0.00022 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 639  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 639 | loss: 0.00022 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 640  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 640 | loss: 0.00022 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 641  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 641 | loss: 0.00022 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 642  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 642 | loss: 0.00022 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 643  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 643 | loss: 0.00022 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 644  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 644 | loss: 0.00022 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 645  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 645 | loss: 0.00022 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 646  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 646 | loss: 0.00022 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 647  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 647 | loss: 0.00021 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 648  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 648 | loss: 0.00021 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 649  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 649 | loss: 0.00021 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 650  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 650 | loss: 0.00021 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 651  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 651 | loss: 0.00021 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 652  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 652 | loss: 0.00021 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 653  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 653 | loss: 0.00021 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 654  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 654 | loss: 0.00021 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 655  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 655 | loss: 0.00021 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 656  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 656 | loss: 0.00021 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 657  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 657 | loss: 0.00021 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 658  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 658 | loss: 0.00021 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 659  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 659 | loss: 0.00021 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 660  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 660 | loss: 0.00021 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 661  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 661 | loss: 0.00021 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 662  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.011s\n",
            "| Adam | epoch: 662 | loss: 0.00021 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 663  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.012s\n",
            "| Adam | epoch: 663 | loss: 0.00021 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 664  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 664 | loss: 0.00021 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 665  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 665 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 666  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 666 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 667  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 667 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 668  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 668 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 669  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 669 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 670  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 670 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 671  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 671 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 672  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 672 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 673  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.016s\n",
            "| Adam | epoch: 673 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 674  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 674 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 675  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 675 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 676  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 676 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 677  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 677 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 678  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 678 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 679  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 679 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 680  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 680 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 681  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 681 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 682  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 682 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 683  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 683 | loss: 0.00020 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 684  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 684 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 685  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 685 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 686  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 686 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 687  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 687 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 688  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 688 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 689  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 689 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 690  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 690 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 691  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 691 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 692  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 692 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 693  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 693 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 694  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 694 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 695  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 695 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 696  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 696 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 697  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 697 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 698  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 698 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 699  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 699 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 700  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 700 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 701  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 701 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 702  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 702 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 703  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 703 | loss: 0.00019 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 704  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 704 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 705  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 705 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 706  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 706 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 707  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 707 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 708  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 708 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 709  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 709 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 710  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 710 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 711  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 711 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 712  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 712 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 713  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 713 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 714  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 714 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 715  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 715 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 716  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 716 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 717  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 717 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 718  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 718 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 719  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 719 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 720  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 720 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 721  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 721 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 722  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 722 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 723  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 723 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 724  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 724 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 725  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 725 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 726  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 726 | loss: 0.00018 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 727  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 727 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 728  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 728 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 729  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 729 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 730  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 730 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 731  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 731 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 732  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 732 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 733  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 733 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 734  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 734 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 735  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 735 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 736  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 736 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 737  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 737 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 738  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 738 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 739  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 739 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 740  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 740 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 741  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 741 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 742  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 742 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 743  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 743 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 744  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 744 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 745  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.008s\n",
            "| Adam | epoch: 745 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 746  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 746 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 747  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 747 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 748  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 748 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 749  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 749 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 750  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 750 | loss: 0.00017 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 751  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 751 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 752  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 752 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 753  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 753 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 754  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 754 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 755  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 755 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 756  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 756 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 757  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 757 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 758  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 758 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 759  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 759 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 760  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 760 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 761  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 761 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 762  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 762 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 763  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 763 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 764  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 764 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 765  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 765 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 766  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 766 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 767  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 767 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 768  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 768 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 769  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 769 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 770  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 770 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 771  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 771 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 772  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 772 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 773  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 773 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 774  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 774 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 775  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 775 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 776  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 776 | loss: 0.00016 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 777  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 777 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 778  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 778 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 779  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 779 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 780  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 780 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 781  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 781 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 782  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 782 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 783  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 783 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 784  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 784 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 785  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 785 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 786  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 786 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 787  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 787 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 788  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 788 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 789  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 789 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 790  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 790 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 791  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 791 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 792  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 792 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 793  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 793 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 794  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 794 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 795  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 795 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 796  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 796 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 797  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 797 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 798  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 798 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 799  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 799 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 800  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 800 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 801  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 801 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 802  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 802 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 803  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 803 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 804  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 804 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 805  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 805 | loss: 0.00015 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 806  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 806 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 807  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 807 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 808  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 808 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 809  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 809 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 810  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 810 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 811  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 811 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 812  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 812 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 813  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 813 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 814  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 814 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 815  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 815 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 816  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 816 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 817  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 817 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 818  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 818 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 819  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 819 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 820  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 820 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 821  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 821 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 822  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 822 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 823  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 823 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 824  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 824 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 825  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 825 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 826  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 826 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 827  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 827 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 828  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 828 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 829  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 829 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 830  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 830 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 831  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 831 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 832  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 832 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 833  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 833 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 834  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 834 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 835  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 835 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 836  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 836 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 837  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 837 | loss: 0.00014 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 838  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 838 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 839  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 839 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 840  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 840 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 841  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 841 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 842  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 842 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 843  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 843 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 844  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 844 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 845  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 845 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 846  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 846 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 847  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 847 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 848  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 848 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 849  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 849 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 850  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 850 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 851  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 851 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 852  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 852 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 853  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 853 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 854  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 854 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 855  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 855 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 856  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 856 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 857  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 857 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 858  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 858 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 859  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 859 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 860  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 860 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 861  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 861 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 862  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 862 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 863  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 863 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 864  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 864 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 865  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 865 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 866  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 866 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 867  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 867 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 868  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 868 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 869  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.012s\n",
            "| Adam | epoch: 869 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 870  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 870 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 871  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 871 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 872  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 872 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 873  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 873 | loss: 0.00013 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 874  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 874 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 875  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 875 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 876  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 876 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 877  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 877 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 878  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 878 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 879  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 879 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 880  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 880 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 881  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 881 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 882  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 882 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 883  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 883 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 884  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 884 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 885  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 885 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 886  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 886 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 887  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 887 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 888  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 888 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 889  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 889 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 890  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 890 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 891  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 891 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 892  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 892 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 893  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 893 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 894  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 894 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 895  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 895 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 896  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 896 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 897  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 897 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 898  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 898 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 899  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 899 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 900  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 900 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 901  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 901 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 902  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 902 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 903  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 903 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 904  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 904 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 905  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 905 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 906  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 906 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 907  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 907 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 908  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 908 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 909  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 909 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 910  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 910 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 911  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 911 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 912  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 912 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 913  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 913 | loss: 0.00012 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 914  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 914 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 915  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 915 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 916  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 916 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 917  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 917 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 918  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 918 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 919  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 919 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 920  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 920 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 921  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 921 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 922  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 922 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 923  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 923 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 924  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 924 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 925  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 925 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 926  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 926 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 927  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 927 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 928  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 928 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 929  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 929 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 930  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 930 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 931  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 931 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 932  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 932 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 933  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 933 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 934  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 934 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 935  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 935 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 936  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 936 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 937  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 937 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 938  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 938 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 939  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 939 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 940  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 940 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 941  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.007s\n",
            "| Adam | epoch: 941 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 942  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 942 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 943  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 943 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 944  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 944 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 945  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 945 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 946  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 946 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 947  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 947 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 948  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 948 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 949  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 949 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 950  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 950 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 951  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 951 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 952  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 952 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 953  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 953 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 954  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 954 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 955  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 955 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 956  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 956 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 957  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 957 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 958  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 958 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 959  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 959 | loss: 0.00011 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 960  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 960 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 961  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 961 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 962  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 962 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 963  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 963 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 964  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 964 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 965  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 965 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 966  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 966 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 967  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 967 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 968  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 968 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 969  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 969 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 970  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 970 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 971  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 971 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 972  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 972 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 973  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 973 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 974  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 974 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 975  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 975 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 976  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 976 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 977  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 977 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 978  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 978 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 979  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 979 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 980  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 980 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 981  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 981 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 982  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 982 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 983  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 983 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 984  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 984 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 985  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 985 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 986  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 986 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 987  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 987 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 988  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 988 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 989  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.007s\n",
            "| Adam | epoch: 989 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 990  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 990 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 991  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 991 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 992  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 992 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 993  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 993 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 994  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 994 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 995  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 995 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 996  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 996 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 997  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 997 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 998  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 998 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 999  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 999 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "Training Step: 1000  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 1000 | loss: 0.00010 - acc: 1.0000 -- iter: 1/1\n",
            "--\n",
            "INFO:tensorflow:/content/model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qod6D6rIR2sx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af0e6ab4-b34c-4be0-cb33-2b402a4a475f"
      },
      "source": [
        "try:\n",
        "    model.load(\"model.tflearn\")\n",
        "except:\n",
        "    model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
        "    model.save(\"model.tflearn\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/model.tflearn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59Av_EqOSlWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bag_of_words(s, words):\n",
        "    bag = [0 for _ in range(len(words))]\n",
        "\n",
        "    s_words = nltk.word_tokenize(s)\n",
        "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
        "    \n",
        "    for se in s_words:\n",
        "        for i, w in enumerate(words):\n",
        "            if w == se:\n",
        "                bag[i] = 1\n",
        "            \n",
        "    return numpy.array(bag)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjOFMHlNgZUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def chat():\n",
        "    print(\"Start talking with the bot (type quit to stop)!\")\n",
        "    while True:\n",
        "        inp = input(\"You: \")\n",
        "        if inp.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        results = model.predict([bag_of_words(inp, words)])\n",
        "        results_index = numpy.argmax(results)\n",
        "        tag = labels[results_index]\n",
        "\n",
        "        for tg in data[\"intents\"]:\n",
        "            if tg['tag'] == tag:\n",
        "                responses = tg['responses']\n",
        "\n",
        "        print(random.choice(responses))"
      ],
      "execution_count": 48,
      "outputs": []
    }
  ]
}